{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "ADPET68xjlzr",
    "tags": []
   },
   "source": [
    "# 第10章: 事前学習済み言語モデル（GPT型）\n",
    "\n",
    "本章では、GPT型（Transformerのデコーダ型）の事前学習済みモデルを利用して、言語生成、評判分析器（ポジネガ分類器）の構築、ファインチューニング、強化学習などに取り組む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "\n",
    "dotenv_path = './.env'\n",
    "load_dotenv(dotenv_path)\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `experiments` has been saved to /home/tosshy/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /home/tosshy/.cache/huggingface/token\n",
      "Login successful.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token $HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"=== Current GPU Usage ===\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "\n",
    "\n",
    "        print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "        print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        print(f\"Available VRAM: {torch.cuda.memory_allocated() / 1e9:.1f} GB\")\n",
    "        print(f\"Cached VRAM: {torch.cuda.memory_reserved() / 1e9:.1f} GB\")\n",
    "\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"\\nGPU {i} ({torch.cuda.get_device_name(i)}):\")\n",
    "            print(f\"  Allocated: {torch.cuda.memory_allocated(i) / 1e9:.1f} GB\")\n",
    "            print(f\"  Reserved: {torch.cuda.memory_reserved(i) / 1e9:.1f} GB\")\n",
    "            print(f\"  Total: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "C1xKmMckti92",
    "tags": []
   },
   "source": [
    "## 90. 次単語予測\n",
    "\n",
    "“The movie was full of\"に続くトークン（トークン列ではなく一つのトークンであることに注意せよ）として適切なもの上位10個と、その確率（尤度）を求めよ。ただし、言語モデルへのプロンプトがどのようなトークン列に変換されたか、確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbdc912478b49bcb3bc1ab882d257b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207c168a5d3a4675bf9bd38738d0e813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af85021560f34ad197a3e2e6b0264f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa300c517f204c1796e14282c35eb6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd42434cfbd34c48982f579219dac023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c562ef7f8b472fac1ab8c4d093158a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-1B-Instruct')\n",
    "model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-1B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Ġmovie', 'Ġwas', 'Ġfull', 'Ġof']\n",
      "[128000, 791, 5818, 574, 2539, 315]\n",
      "<|begin_of_text|>The movie was full of\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The movie was full of'\n",
    "\n",
    "encoded = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "tokenized = tokenizer.tokenize(sentence)\n",
    "print(tokenized)\n",
    "\n",
    "input_ids = tokenizer(sentence).input_ids\n",
    "print(input_ids)\n",
    "\n",
    "decoded = tokenizer.decode(input_ids)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,    791,   5818,    574,   2539,    315]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]], device='cuda:1')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 実験：各系列における尤度が最大のものを選んだ結果\n",
    "model.to(device)\n",
    "encoded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000,    791,   5818,    574,   2539,    315]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]], device='cuda:1')}\n",
      "Next token id: 1957\n",
      "Next token:  action\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "encoded.to(device)\n",
    "\n",
    "print(encoded)\n",
    "\n",
    "outputs = model(**encoded)\n",
    "logits = outputs.logits # {batch_size, seq_len, vocab_size}\n",
    "# logits[:, k, :]はinput_ids[k-1]までを使って計算されたスコア\n",
    "next_token_logits = logits[:, -1, :]\n",
    "next_token_id = next_token_logits.argmax(-1).item()\n",
    "print(f'Next token id: {next_token_id}')\n",
    "next_token = tokenizer.decode([next_token_id])\n",
    "print(f'Next token: {next_token}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 next tokens\n",
      "1. Token:  action, Probability: 0.0852\n",
      "2. Token:  suspense, Probability: 0.0344\n",
      "3. Token:  drama, Probability: 0.0242\n",
      "4. Token:  excitement, Probability: 0.0190\n",
      "5. Token:  great, Probability: 0.0189\n",
      "6. Token:  surprises, Probability: 0.0155\n",
      "7. Token:  interesting, Probability: 0.0143\n",
      "8. Token:  twists, Probability: 0.0136\n",
      "9. Token:  exciting, Probability: 0.0132\n",
      "10. Token:  memorable, Probability: 0.0099\n"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "top_k_probs, top_k_indices = torch.topk(next_token_probs, top_k) # (batch_size, top_k)\n",
    "\n",
    "print(f'Top {top_k} next tokens')\n",
    "for i in range(top_k):\n",
    "    token_id = top_k_indices[0, i].item()\n",
    "    token = tokenizer.decode([token_id])\n",
    "    prob = top_k_probs[0, i].item()\n",
    "    print(f'{i+1}. Token: {token}, Probability: {prob:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "s1RhOldA0meh",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 91. 続きのテキストの予測\n",
    "\n",
    "“The movie was full of\"に続くテキストを複数予測せよ。このとき、デコーディングの方法や温度パラメータ（temperature）を変えながら、予測される複数のテキストの変化を観察せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'The movie was full of'\n",
    "encoded = tokenizer(prompt, return_tensors='pt')\n",
    "input_ids = encoded.input_ids.to(device)\n",
    "attention_mask = encoded.attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Default (Greedy-like) ---\n",
      "The movie was full of memorable characters, exciting plot twists, and stunning visuals. But, what made it truly unforgettable was the emotional resonance it brought to the audience.\n",
      "\n",
      "For many viewers, the movie was a powerful reminder of the human experience. It\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Greedy Searchに近い\n",
    "print('--- Default (Greedy-like) ---')\n",
    "outputs_default = model.generate(input_ids, attention_mask=attention_mask, max_length=50, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs_default[0], skip_special_tokens=True))\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sampling with Temperature (0.7) ---\n",
      "The movie was full of memorable moments, but one scene that really stands out to me is the infamous \"I'm a little tea pot\" line from the character, Willy Wonka.\n",
      "\n",
      "I remember being so mesmerized by the way Charlie Bucket\n",
      "------------------------------\n",
      "--- Sampling with Temperature (1.5) ---\n",
      "The movie was full of exciting moments but, in the final cut, only these few scenes were retained.\n",
      "The scenes that were omitted are the first shot of an empty theater, where it is left to believe that it has stood vacant.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# サンプリング (do_sample=True) と Temperature\n",
    "# Temperature < 1.0 : より決定的\n",
    "# Temperature > 1.0 : よりランダム\n",
    "print('--- Sampling with Temperature (0.7) ---')\n",
    "outputs_temp_low = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(tokenizer.decode(outputs_temp_low[0], skip_special_tokens=True))\n",
    "print('-' * 30)\n",
    "\n",
    "print('--- Sampling with Temperature (1.5) ---')\n",
    "outputs_temp_high = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    temperature=1.5,\n",
    "    top_k=50,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(tokenizer.decode(outputs_temp_high[0], skip_special_tokens=True))\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top-k Sampling (k=30) ---\n",
      "The movie was full of action and suspense, but it was the way the characters interacted with each other that made it truly unforgettable.\n",
      "I remember the movie like it was yesterday. I was a teenager at the time, and I had seen the\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Top-k サンプリング\n",
    "# 次のトークンを予測する際に，確率上位k個の中からサンプリングする\n",
    "print('--- Top-k Sampling (k=30) ---')\n",
    "outputs_top_k = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    top_k=30,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(tokenizer.decode(outputs_top_k[0], skip_special_tokens=True))\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top-p (Nucleus) Sampling (p=0.9) ---\n",
      "The movie was full of surprises, but one of the most memorable moments was when the main character, a young girl named Lily, found out that her mother was a famous actress. She had always known that her mother was famous, but she had\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Top-p (Nucleus) サンプリング\n",
    "# 確率の累積がpを超える最小のトークンセットからサンプリングする\n",
    "print('--- Top-p (Nucleus) Sampling (p=0.9) ---')\n",
    "outputs_top_p = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    top_k=0, # top_kとtop_pは通常どちらか一方を指定するか、top_k=0でtop_pを有効にする\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(tokenizer.decode(outputs_top_p[0], skip_special_tokens=True))\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Beam Search (num_beams=5) ---\n",
      "The movie was full of action, suspense, and romance. The plot was engaging, and the characters were well-developed and relatable. The special effects were impressive, and the cinematography was stunning. Overall, the movie was a thrilling ride\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. ビームサーチ\n",
    "# 複数の候補 (ビーム) を保持しながら探索する\n",
    "print(\"--- Beam Search (num_beams=5) ---\")\n",
    "outputs_beam = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=50,\n",
    "    num_beams=5,\n",
    "    early_stopping=True, # EOSトークンが出たら早めに打ち切る\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(tokenizer.decode(outputs_beam[0], skip_special_tokens=True))\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Beam Search with num_return_sequences=3 ---\n",
      "Output 1: The movie was full of action, suspense, and romance. The plot was engaging, and the characters were well-developed and relatable. The special effects were impressive, and the cinematography was stunning. Overall, the movie was a thrilling ride\n",
      "Output 2: The movie was full of action, suspense, and romance. The plot was engaging, and the characters were well-developed and relatable. The special effects were impressive, and the cinematography was stunning. Overall, I would highly recommend this movie\n",
      "Output 3: The movie was full of action, suspense, and romance. The plot was engaging, and the characters were well-developed and relatable. The special effects were impressive, and the cinematography was stunning. Overall, the movie was a thrilling and\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 複数の異なる出力を得るために num_return_sequences を使用\n",
    "print(\"--- Beam Search with num_return_sequences=3 ---\")\n",
    "outputs_beam_multiple = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=50,\n",
    "    num_beams=5,\n",
    "    num_return_sequences=3,\n",
    "    early_stopping=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "for i, output in enumerate(outputs_beam_multiple):\n",
    "    print(f\"Output {i+1}: {tokenizer.decode(output, skip_special_tokens=True)}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "7ZFadg6B8VdA",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 92. 予測されたテキストの確率を計算\n",
    "\n",
    "“The movie was full of\"に続くテキストを予測し、生成された各単語の尤度を表示せよ（生成されるテキストが長いと出力が読みにくくなるので、適当な長さで生成を打ち切るとよい）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'The movie was full of'\n",
    "encoded = tokenizer(prompt, return_tensors='pt')\n",
    "input_ids = encoded.input_ids.to(device)\n",
    "attention_mask = encoded.attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input prompt: The movie was full of\n",
      "Generated tokens and their probabilities:\n",
      "Token: ' action', Probability: 0.5336\n",
      "Token: ',', Probability: 0.5750\n",
      "Token: ' suspense', Probability: 0.8670\n",
      "Token: ',', Probability: 1.0000\n",
      "Token: ' and', Probability: 1.0000\n",
      "Token: ' romance', Probability: 0.6102\n",
      "Token: ',', Probability: 0.3331\n",
      "Token: ' but', Probability: 0.3680\n",
      "Token: ' it', Probability: 0.4549\n",
      "Token: ' was', Probability: 0.6033\n",
      "Token: ' also', Probability: 0.7383\n",
      "Token: ' a', Probability: 0.8530\n",
      "Token: ' thought', Probability: 0.0197\n",
      "Token: '-pro', Probability: 1.0000\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids, \n",
    "    attention_mask=attention_mask, \n",
    "    max_length=20, \n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True\n",
    ")\n",
    "\n",
    "sequences = list(outputs.sequences.squeeze(0))\n",
    "scores = outputs.scores\n",
    "\n",
    "prompt_len = input_ids.shape[1]\n",
    "\n",
    "print(f\"Input prompt: {tokenizer.decode(sequences[:prompt_len], skip_special_tokens=True)}\")\n",
    "print(\"Generated tokens and their probabilities:\")\n",
    "\n",
    "for k in range(len(scores)):\n",
    "    current_token_idx_in_sequence = prompt_len + k\n",
    "\n",
    "    generated_token_id = sequences[current_token_idx_in_sequence]\n",
    "\n",
    "    generated_token_str = tokenizer.decode([generated_token_id])\n",
    "\n",
    "    step_logits = scores[k]\n",
    "\n",
    "    step_probs = torch.softmax(step_logits, dim=-1).squeeze()\n",
    "\n",
    "    prob_of_generated_token = step_probs[generated_token_id].item()\n",
    "\n",
    "    print(f\"Token: '{generated_token_str}', Probability: {prob_of_generated_token:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "FvNCTMj6OegF",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 93. パープレキシティ\n",
    "\n",
    "適当な文を準備して、事前学習済み言語モデルでパープレキシティを測定せよ。例えば、\n",
    "\n",
    "+ The movie was full of surprises\n",
    "+ The movies were full of surprises\n",
    "+ The movie were full of surprises\n",
    "+ The movies was full of surprises\n",
    "\n",
    "の4文に対して、パープレキシティを測定して観察せよ（最後の2つの文は故意に文法的な間違いを入れた）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'The movie was full of surprises',\n",
    "    'The movies were full of surprises',\n",
    "    'The movie were full of surprises',\n",
    "    'The movies was full of surprises'\n",
    "]\n",
    "\n",
    "encoded = tokenizer(sentences, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,    791,   5818,    574,   2539,    315,  46540],\n",
       "        [128000,    791,   9698,   1051,   2539,    315,  46540],\n",
       "        [128000,    791,   5818,   1051,   2539,    315,  46540],\n",
       "        [128000,    791,   9698,    574,   2539,    315,  46540]],\n",
       "       device='cuda:1'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1]], device='cuda:1')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "encoded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The movie was full of surprises, Perplexity: 159.2811737060547\n",
      "Sentence: The movies were full of surprises, Perplexity: 265.9172668457031\n",
      "Sentence: The movie were full of surprises, Perplexity: 460.8365173339844\n",
      "Sentence: The movies was full of surprises, Perplexity: 407.7308349609375\n"
     ]
    }
   ],
   "source": [
    "input_ids = encoded.input_ids\n",
    "outputs = model(**encoded)\n",
    "logits = outputs.logits\n",
    "\n",
    "for i in range(logits.shape[0]):\n",
    "    current_prediction_logits = logits[i, :-1, :]\n",
    "    current_target_ids = input_ids[i, 1:]\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    mean_neg_log_likelihood = criterion(current_prediction_logits, current_target_ids)\n",
    "\n",
    "    ppl = torch.exp(mean_neg_log_likelihood)\n",
    "    print(f'Sentence: {sentences[i]}, Perplexity: {ppl.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-7fB-n9suYg"
   },
   "source": [
    "## 94. チャットテンプレート\n",
    "\n",
    "\"What do you call a sweet eaten after dinner?\"という問いかけに対する応答を生成するため、チャットテンプレートを適用し、言語モデルに与えるべきプロンプトを作成せよ。また、そのプロンプトに対する応答を生成し、表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated prompt:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 01 Jun 2025\n",
      "\n",
      "Answer the following question.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What do you call a sweet eaten after dinner?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "instruction = 'Answer the following question.'\n",
    "text = 'What do you call a sweet eaten after dinner?'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": instruction},\n",
    "    {\"role\": \"user\", \"content\": text}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print('Generated prompt:')\n",
    "print(prompt)\n",
    "print('=' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "I don't know what you're asking, but I can try to help. Is the answer \"dessert\"?\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "if 'token_type_ids' in inputs:\n",
    "    inputs.pop('token_type_ids')\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "print('Model response:')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "PT-bk0XWIZ2E",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 95. マルチターンのチャット\n",
    "\n",
    "問題94で生成された応答に対して、追加で\"Please give me the plural form of the word with its spelling in reverse order.\"と問いかけたときの応答を生成・表示せよ。また、その時に言語モデルに与えるプロンプトを確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-turn chat prompt\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 01 Jun 2025\n",
      "\n",
      "Answer the following question.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What do you call a sweet eaten after dinner?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I don't know what you're asking, but I can try to help. Is the answer \"dessert\"?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Please give me the plural form of the word with its spelling in reverse order.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "previous_response = response\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": instruction},\n",
    "    {\"role\": \"user\", \"content\": \"What do you call a sweet eaten after dinner?\"},\n",
    "    {\"role\": \"assistant\", \"content\": previous_response},\n",
    "    {\"role\": \"user\", \"content\": \"Please give me the plural form of the word with its spelling in reverse order.\"}\n",
    "]\n",
    "\n",
    "multi_turn_prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print('Multi-turn chat prompt')\n",
    "print(multi_turn_prompt)\n",
    "print('=' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-turn response:\n",
      "The word \"dessert\" spelled in reverse order is \"trseSSED\".\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(multi_turn_prompt, return_tensors='pt')\n",
    "if 'token_type_ids' in inputs:\n",
    "    inputs.pop('token_type_ids')\n",
    "inputs = inputs.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "multi_turn_response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "print('Multi-turn response:')\n",
    "print(multi_turn_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "qH0YortL0afd",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 96. プロンプトによる感情分析\n",
    "\n",
    "事前学習済み言語モデルで感情分析を行いたい。テキストを含むプロンプトを事前学習済み言語モデルに与え、（ファインチューニングは行わずに）テキストのポジネガを予測するという戦略で、[SST-2](https://dl.fbaipublicfiles.com/glue/data/SST-2.zip)の開発データにおける正解率を測定せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('llm-jp/llm-jp-3-150m-instruct3')\n",
    "model = AutoModelForCausalLM.from_pretrained('llm-jp/llm-jp-3-150m-instruct3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67344</th>\n",
       "      <td>a delightful comedy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67345</th>\n",
       "      <td>anguish , anger and frustration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67346</th>\n",
       "      <td>at achieving the modest , crowd-pleasing goals...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67347</th>\n",
       "      <td>a patient viewer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67348</th>\n",
       "      <td>this new jangle of noise , mayhem and stupidit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67349 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0           hide new secretions from the parental units       0\n",
       "1                   contains no wit , only labored gags       0\n",
       "2      that loves its characters and communicates som...      1\n",
       "3      remains utterly satisfied to remain the same t...      0\n",
       "4      on the worst revenge-of-the-nerds clichés the ...      0\n",
       "...                                                  ...    ...\n",
       "67344                               a delightful comedy       1\n",
       "67345                   anguish , anger and frustration       0\n",
       "67346  at achieving the modest , crowd-pleasing goals...      1\n",
       "67347                                  a patient viewer       1\n",
       "67348  this new jangle of noise , mayhem and stupidit...      0\n",
       "\n",
       "[67349 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = './data/SST-2/train.tsv'\n",
    "dev_path = './data/SST-2/dev.tsv'\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "dev_df = pd.read_csv(dev_path, sep='\\t')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences:   0%|                                                                                                                                                                                | 0/872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [02:03<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 872\n",
      "Correct predictions: 0\n",
      "Unable to predict: 872\n",
      "Wrong predictions: 0\n",
      "Accuracy: 0.0000 (0/872)\n",
      "Unable to predict rate: 1.0000 (872/872)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dev_sentences = dev_df.sentence\n",
    "dev_labels = dev_df.label\n",
    "\n",
    "predictions = []\n",
    "\n",
    "instruction = '以下の文がポジティブかネガティブのどちらなのか判定してください．\"ポジティブ\"か\"ネガティブ\"で回答してください．'\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for i in tqdm(range(len(dev_sentences)), desc='Processing sentences'):\n",
    "    sentence = dev_sentences.iloc[i]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": sentence}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    if 'token_type_ids' in inputs:\n",
    "        inputs.pop('token_type_ids')\n",
    "    inputs = inputs.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=15,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    predictions.append(response.strip())\n",
    "\n",
    "correct = 0\n",
    "unable_to_predict = 0\n",
    "for i, pred in enumerate(predictions):\n",
    "    true_label = dev_labels.iloc[i]\n",
    "    pred_lower = pred.lower()\n",
    "\n",
    "    if true_label == 1 and 'ポジティブ' in pred_lower:\n",
    "        correct += 1\n",
    "    elif true_label == 0 and 'ネガティブ' in pred_lower:\n",
    "        correct += 1\n",
    "    elif 'ポジティブ' not in pred_lower and 'ネガティブ' not in pred_lower:\n",
    "        unable_to_predict += 1\n",
    "\n",
    "total = len(predictions)\n",
    "accuracy = correct / total\n",
    "unable_rate = unable_to_predict / total\n",
    "\n",
    "print(f'Total samples: {total}')\n",
    "print(f'Correct predictions: {correct}')\n",
    "print(f'Unable to predict: {unable_to_predict}')\n",
    "print(f'Wrong predictions: {total - correct - unable_to_predict}')\n",
    "print(f'Accuracy: {accuracy:.4f} ({correct}/{total})')\n",
    "print(f'Unable to predict rate: {unable_rate:.4f} ({unable_to_predict}/{total})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of unable to predict:\n",
      "  Sentence: \"it 's a charming and often affecting journey . \"\n",
      "  Prediction: \"「it 's a charming and often affecting journey .」は、直訳すると\"\n",
      "  True label: 1\n",
      "--------------------------------------------------\n",
      "  Sentence: \"unflinchingly bleak and desperate \"\n",
      "  Prediction: \"「unflinchingly bleak and desperate」は、直訳すると「絶望\"\n",
      "  True label: 0\n",
      "--------------------------------------------------\n",
      "  Sentence: \"allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . \"\n",
      "  Prediction: \"Among the many reasons why a filmmaker might be poised to embar\"\n",
      "  True label: 1\n",
      "--------------------------------------------------\n",
      "  Sentence: \"the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . \"\n",
      "  Prediction: \"質問内容は個人のプライバシーを尊重し、個人情報保護の観点から\"\n",
      "  True label: 1\n",
      "--------------------------------------------------\n",
      "  Sentence: \"it 's slow -- very , very slow . \"\n",
      "  Prediction: \"「it 's slow -- very , very slow .」は、英語の\"\n",
      "  True label: 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if unable_to_predict > 0:\n",
    "    print(f'\\nExamples of unable to predict:')\n",
    "    count = 0\n",
    "    for i, pred in enumerate(predictions):\n",
    "        pred_lower = pred.lower()\n",
    "        if 'ポジティブ' not in pred_lower and 'ネガティブ' not in pred_lower:\n",
    "            print(f'  Sentence: \"{dev_sentences.iloc[i]}\"')\n",
    "            print(f'  Prediction: \"{pred}\"')\n",
    "            print(f'  True label: {dev_labels.iloc[i]}')\n",
    "            print('-' * 50)\n",
    "            count += 1\n",
    "            if count >= 5:  # 最初の5件だけ表示\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "giA6FivrKaSf",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 97. 埋め込みに基づく感情分析\n",
    "\n",
    "事前学習済み言語モデルでテキストをベクトルで表現（エンコード）し、そのベクトルにフィードフォワード層を通すことで極性ラベルを予測するモデルを学習せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama3.2-3B-InstuructをQLoRAでチューニングした場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, LlamaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = './data/SST-2/train.tsv'\n",
    "dev_path = './data/SST-2/dev.tsv'\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "dev_df = pd.read_csv(dev_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "\n",
    "dotenv_path = './.env'\n",
    "load_dotenv(dotenv_path)\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaBinaryClassifier(nn.Module):\n",
    "    def __init__(self, llama_model, hidden_size):\n",
    "        super().__init__()\n",
    "        self.llama_model = llama_model\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        for param in self.llama_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.llama_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            use_cache=False\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            masked_hidden = hidden_states.clone()\n",
    "            masked_hidden[attention_mask == 0] = float('-inf')\n",
    "            pooled = torch.max(masked_hidden, dim=1)[0]\n",
    "        else:\n",
    "            pooled = torch.max(hidden_states, dim=1)[0]\n",
    "\n",
    "        pooled = self.dropout(pooled)\n",
    "        logits = self.classifier(pooled)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_length=256):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = str(self.sentences.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding.input_ids.flatten(),\n",
    "            'attention_mask': encoding.attention_mask.flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and base LlamaModel...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1239af76d740dfad8af9ceb92417a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading tokenizer and base LlamaModel...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-3B-Instruct')\n",
    "model = LlamaModel.from_pretrained(\n",
    "    'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    device_map='auto',\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:\n",
      "layers.0.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.12.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.12.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.12.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.12.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.12.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.12.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.12.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.13.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.13.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.13.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.13.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.13.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.13.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.13.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.14.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.14.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.14.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.14.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.14.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.14.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.14.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.15.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.15.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.15.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.15.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.15.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.15.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.15.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.16.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.16.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.16.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.16.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.16.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.16.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.16.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.17.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.17.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.17.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.17.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.17.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.17.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.17.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.18.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.18.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.18.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.18.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.18.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.18.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.18.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.19.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.19.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.19.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.19.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.19.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.19.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.19.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.20.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.20.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.20.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.20.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.20.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.20.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.20.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.21.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.21.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.21.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.21.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.21.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.21.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.21.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.22.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.22.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.22.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.22.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.22.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.22.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.22.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.23.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.23.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.23.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.23.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.23.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.23.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.23.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.24.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.24.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.24.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.24.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.24.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.24.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.24.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.25.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.25.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.25.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.25.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.25.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.25.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.25.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.26.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.26.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.26.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.26.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.26.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.26.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.26.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.27.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.27.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.27.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.27.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.27.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.27.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.27.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "\n",
      "Model attributes:\n",
      "['_convert_head_mask_to_5d', '_copy_lm_head_original_to_resized', '_get_resized_lm_head', '_init_added_lm_head_bias_with_mean', '_init_added_lm_head_weights_with_mean', 'get_head_mask', 'prune_heads']\n",
      "\n",
      "Model config: LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure:\")\n",
    "for name, module in model.named_modules():\n",
    "    if 'head' in name.lower() or 'output' in name.lower() or 'proj' in name.lower():\n",
    "        print(f\"{name}: {type(module)}\")\n",
    "\n",
    "print(\"\\nModel attributes:\")\n",
    "print([attr for attr in dir(model) if 'head' in attr.lower()])\n",
    "\n",
    "print(f\"\\nModel config: {model.config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up padding token...\n",
      "Set pad_token to: <|eot_id|>\n",
      "Set model pad_token_id to: 128009\n",
      "tokenizer.pad_token: <|eot_id|>\n",
      "tokenizer.pad_token_id: 128009\n",
      "tokenizer.eos_token: <|eot_id|>\n",
      "tokenizer.eos_token_id: 128009\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up padding token...\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(f\"Set pad_token to: {tokenizer.pad_token}\")\n",
    "\n",
    "if hasattr(model, 'config'):\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    print(f\"Set model pad_token_id to: {model.config.pad_token_id}\")\n",
    "\n",
    "print(f\"tokenizer.pad_token: {tokenizer.pad_token}\")\n",
    "print(f\"tokenizer.pad_token_id: {tokenizer.pad_token_id}\")\n",
    "print(f\"tokenizer.eos_token: {tokenizer.eos_token}\")\n",
    "print(f\"tokenizer.eos_token_id: {tokenizer.eos_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size: 3072\n"
     ]
    }
   ],
   "source": [
    "hidden_size = model.config.hidden_size\n",
    "print(f'Hidden size: {hidden_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_4bit(W: torch.Tensor):\n",
    "    # per-row scale\n",
    "    maxv = W.abs().amax(dim=1, keepdim=True) # (out, 1)\n",
    "    scale = maxv / 7.0\n",
    "    Wq = torch.clamp((W / scale).round(), -8, 7).to(torch.int8)\n",
    "    return Wq, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantLinear(nn.Module):\n",
    "    def __init__(self, linear: nn.Linear):\n",
    "        super().__init__()\n",
    "        W = linear.weight.data # (out, in)\n",
    "        Wq, scale = quantize_4bit(W)\n",
    "        self.register_buffer('Wq', Wq)\n",
    "        self.register_buffer('scale', scale)\n",
    "        if linear.bias is not None:\n",
    "            self.bias = nn.Parameter(linear.bias.data.clone())\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # dequantize on the fly\n",
    "        W = self.Wq.float() * self.scale\n",
    "        return F.linear(x, W, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, r=8, alpha=16):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "        self.scaling = alpha / r\n",
    "        self.down = nn.Linear(in_features, r, bias=False)\n",
    "        self.up   = nn.Linear(r, out_features, bias=False)\n",
    "        nn.init.kaiming_uniform_(self.down.weight, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.up.weight)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.up(self.down(x)) * self.scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantLoRALinear(nn.Module):\n",
    "    def __init__(self, linear: nn.Linear, r=8, alpha=16):\n",
    "        super().__init__()\n",
    "        self.quant = QuantLinear(linear)\n",
    "        self.lora = LoRALinear(linear.in_features, linear.out_features, r=r, alpha=alpha)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.quant(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_qlora(\n",
    "        model, \n",
    "        target_substrings=(\n",
    "            # Attention\n",
    "            'q_proj','v_proj','k_proj','o_proj'\n",
    "            # MLP (FFN)\n",
    "            # 'gate_proj', 'down_proj', 'up_proj'\n",
    "        )\n",
    "    ):\n",
    "    for name, module in list(model.named_modules()):\n",
    "        if isinstance(module, nn.Linear) and any(s in name for s in target_substrings):\n",
    "            parent_name, attr = name.rsplit('.', 1)\n",
    "            parent_mod = dict(model.named_modules())[parent_name]\n",
    "            setattr(parent_mod,\n",
    "                    attr,\n",
    "                    QuantLoRALinear(module, r=8, alpha=16)\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = LlamaBinaryClassifier(model, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in classifier_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "apply_qlora(classifier_model)\n",
    "for p in classifier_model.modules():\n",
    "    if isinstance(p, LoRALinear):\n",
    "        for sub in (p.down, p.up):\n",
    "            for q in sub.parameters():\n",
    "                q.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = SST2Dataset(train_df.sentence, train_df.label, tokenizer, max_length)\n",
    "dev_dataset = SST2Dataset(dev_df.sentence, dev_df.label, tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=16,\n",
    "    pin_memory=True\n",
    ")\n",
    "dev_loader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=16,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "\n",
    "lora_params = [p for p in classifier_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(lora_params, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Current GPU Usage ===\n",
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "GPU: NVIDIA RTX A4500\n",
      "Total VRAM: 21.0 GB\n",
      "Available VRAM: 10.7 GB\n",
      "Cached VRAM: 13.6 GB\n",
      "\n",
      "GPU 0 (NVIDIA RTX A4500):\n",
      "  Allocated: 10.7 GB\n",
      "  Reserved: 13.6 GB\n",
      "  Total: 21.0 GB\n"
     ]
    }
   ],
   "source": [
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "classifier_model, optimizer, train_loader, dev_loader = accelerator.prepare(\n",
    "    classifier_model, optimizer, train_loader, dev_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaBinaryClassifier(\n",
       "  (llama_model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): QuantLoRALinear(\n",
       "            (quant): QuantLinear()\n",
       "            (lora): LoRALinear(\n",
       "              (down): Linear(in_features=3072, out_features=8, bias=False)\n",
       "              (up): Linear(in_features=8, out_features=3072, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (k_proj): QuantLoRALinear(\n",
       "            (quant): QuantLinear()\n",
       "            (lora): LoRALinear(\n",
       "              (down): Linear(in_features=3072, out_features=8, bias=False)\n",
       "              (up): Linear(in_features=8, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (v_proj): QuantLoRALinear(\n",
       "            (quant): QuantLinear()\n",
       "            (lora): LoRALinear(\n",
       "              (down): Linear(in_features=3072, out_features=8, bias=False)\n",
       "              (up): Linear(in_features=8, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (o_proj): QuantLoRALinear(\n",
       "            (quant): QuantLinear()\n",
       "            (lora): LoRALinear(\n",
       "              (down): Linear(in_features=3072, out_features=8, bias=False)\n",
       "              (up): Linear(in_features=8, out_features=3072, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (classifier): Linear(in_features=3072, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "classifier_model.to(accelerator.device)\n",
    "classifier_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters:     2512.70M\n",
      "Trainable parameters: 4.59M\n"
     ]
    }
   ],
   "source": [
    "def print_model_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters:     {total/1e6:.2f}M\")\n",
    "    print(f\"Trainable parameters: {trainable/1e6:.2f}M\")\n",
    "\n",
    "print_model_params(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|                                                                                                                                                                      | 0/8419 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 19.57 GiB of which 5.00 MiB is free. Including non-PyTorch memory, this process has 19.55 GiB memory in use. Of the allocated memory 19.10 GiB is allocated by PyTorch, and 237.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m accelerator.autocast():\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     logits = \u001b[43mclassifier_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     loss = criterion(logits.squeeze(-\u001b[32m1\u001b[39m), labels)\n\u001b[32m     15\u001b[39m accelerator.backward(loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mLlamaBinaryClassifier.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllama_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     hidden_states = outputs.hidden_states[-\u001b[32m1\u001b[39m]\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    451\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:308\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    305\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:265\u001b[39m, in \u001b[36mLlamaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m         attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    277\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/2025/ch10/.venv/lib/python3.11/site-packages/transformers/integrations/sdpa_attention.py:54\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.jit.is_tracing() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(is_causal, torch.Tensor):\n\u001b[32m     52\u001b[39m     is_causal = is_causal.item()\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 19.57 GiB of which 5.00 MiB is free. Including non-PyTorch memory, this process has 19.55 GiB memory in use. Of the allocated memory 19.10 GiB is allocated by PyTorch, and 237.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        with accelerator.autocast():\n",
    "            logits = classifier_model(input_ids, attention_mask)\n",
    "            loss = criterion(logits.squeeze(-1), labels)\n",
    "        \n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 218/218 [02:07<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Set Accuracy: 0.9633\n",
      "GPU: NVIDIA RTX A4500\n",
      "Total VRAM: 21.0 GB\n",
      "Available VRAM: 10.8 GB\n",
      "Cached VRAM: 19.8 GB\n",
      "\n",
      "Prediction examples:\n",
      "Sentence: it 's a charming and often affecting journey . \n",
      "True label: 1 (Positive)\n",
      "Predicted: 1 (Positive)\n",
      "Correct: True\n",
      "--------------------------------------------------\n",
      "Sentence: unflinchingly bleak and desperate \n",
      "True label: 0 (Negative)\n",
      "Predicted: 0 (Negative)\n",
      "Correct: True\n",
      "--------------------------------------------------\n",
      "Sentence: allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . \n",
      "True label: 1 (Positive)\n",
      "Predicted: 1 (Positive)\n",
      "Correct: True\n",
      "--------------------------------------------------\n",
      "Sentence: the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . \n",
      "True label: 1 (Positive)\n",
      "Predicted: 1 (Positive)\n",
      "Correct: True\n",
      "--------------------------------------------------\n",
      "Sentence: it 's slow -- very , very slow . \n",
      "True label: 0 (Negative)\n",
      "Predicted: 0 (Negative)\n",
      "Correct: True\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 評価\n",
    "classifier_model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dev_loader, desc='Evaluating'):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        logits = classifier_model(input_ids, attention_mask)\n",
    "        predictions = torch.sigmoid(logits.squeeze(-1)) > 0.5\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 精度の計算\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f'Development Set Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# メモリ使用量の最終チェック\n",
    "check_gpu_memory()\n",
    "\n",
    "# いくつかの予測例を表示\n",
    "print(\"\\nPrediction examples:\")\n",
    "for i in range(5):\n",
    "    sentence = dev_df['sentence'].iloc[i]\n",
    "    true_label = dev_df['label'].iloc[i]\n",
    "    pred_label = int(all_predictions[i])\n",
    "    \n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"True label: {true_label} ({'Positive' if true_label == 1 else 'Negative'})\")\n",
    "    print(f\"Predicted: {pred_label} ({'Positive' if pred_label == 1 else 'Negative'})\")\n",
    "    print(f\"Correct: {true_label == pred_label}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### llm-jp-3-150m-instruct3をフルファインチューニングした場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = './data/SST-2/train.tsv'\n",
    "dev_path = './data/SST-2/dev.tsv'\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "dev_df = pd.read_csv(dev_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlmjpBinaryClassifier(nn.Module):\n",
    "    def __init__(self, llmjp_model, hidden_size):\n",
    "        super().__init__()\n",
    "        self.llmjp_model = llmjp_model\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        for param in self.llmjp_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.llmjp_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            use_cache=False\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            masked_hidden = hidden_states.clone()\n",
    "            masked_hidden[attention_mask == 0] = float('-inf')\n",
    "            pooled = torch.max(masked_hidden, dim=1)[0]\n",
    "        else:\n",
    "            pooled = torch.max(hidden_states, dim=1)[0]\n",
    "\n",
    "        pooled = self.dropout(pooled)\n",
    "        logits = self.classifier(pooled)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_length=256):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = str(self.sentences.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding.input_ids.flatten(),\n",
    "            'attention_mask': encoding.attention_mask.flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and base LLMJPModel...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer and base LLMJPModel...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('llm-jp/llm-jp-3-150m-instruct3')\n",
    "model = AutoModel.from_pretrained(\n",
    "    'llm-jp/llm-jp-3-150m-instruct3',\n",
    "    device_map={\"\": 1},\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:\n",
      "layers.0.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.0.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.1.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.2.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.3.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.4.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.5.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.6.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.7.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.8.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.9.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.10.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.self_attn.q_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.self_attn.k_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.self_attn.v_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.self_attn.o_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.mlp.gate_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.mlp.up_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "layers.11.mlp.down_proj: <class 'torch.nn.modules.linear.Linear'>\n",
      "\n",
      "Model attributes:\n",
      "['_convert_head_mask_to_5d', '_copy_lm_head_original_to_resized', '_get_resized_lm_head', '_init_added_lm_head_bias_with_mean', '_init_added_lm_head_weights_with_mean', 'get_head_mask', 'prune_heads']\n",
      "\n",
      "Model config: LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 99584\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure:\")\n",
    "for name, module in model.named_modules():\n",
    "    if 'head' in name.lower() or 'output' in name.lower() or 'proj' in name.lower():\n",
    "        print(f\"{name}: {type(module)}\")\n",
    "\n",
    "print(\"\\nModel attributes:\")\n",
    "print([attr for attr in dir(model) if 'head' in attr.lower()])\n",
    "\n",
    "print(f\"\\nModel config: {model.config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up padding token...\n",
      "Set model pad_token_id to: 4\n",
      "tokenizer.pad_token: <PAD|LLM-jp>\n",
      "tokenizer.pad_token_id: 4\n",
      "tokenizer.eos_token: </s>\n",
      "tokenizer.eos_token_id: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up padding token...\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(f\"Set pad_token to: {tokenizer.pad_token}\")\n",
    "\n",
    "if hasattr(model, 'config'):\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    print(f\"Set model pad_token_id to: {model.config.pad_token_id}\")\n",
    "\n",
    "print(f\"tokenizer.pad_token: {tokenizer.pad_token}\")\n",
    "print(f\"tokenizer.pad_token_id: {tokenizer.pad_token_id}\")\n",
    "print(f\"tokenizer.eos_token: {tokenizer.eos_token}\")\n",
    "print(f\"tokenizer.eos_token_id: {tokenizer.eos_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size: 512\n"
     ]
    }
   ],
   "source": [
    "hidden_size = model.config.hidden_size\n",
    "print(f'Hidden size: {hidden_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = LlmjpBinaryClassifier(model, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset = SST2Dataset(train_df.sentence, train_df.label, tokenizer, max_length)\n",
    "dev_dataset = SST2Dataset(dev_df.sentence, dev_df.label, tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=16,\n",
    "    pin_memory=True\n",
    ")\n",
    "dev_loader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=16,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(classifier_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "classifier_model, optimizer, train_loader, dev_loader = accelerator.prepare(\n",
    "    classifier_model, optimizer, train_loader, dev_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlmjpBinaryClassifier(\n",
       "  (llmjp_model): LlamaModel(\n",
       "    (embed_tokens): Embedding(99584, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (down_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((512,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((512,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((512,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "classifier_model.to(accelerator.device)\n",
    "classifier_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16838/16838 [04:41<00:00, 59.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.5494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16838/16838 [04:41<00:00, 59.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.5473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16838/16838 [04:41<00:00, 59.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16838/16838 [04:41<00:00, 59.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16838/16838 [04:41<00:00, 59.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.5461\n",
      "Training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        with accelerator.autocast():\n",
    "            logits = classifier_model(input_ids, attention_mask)\n",
    "            loss = criterion(logits.squeeze(-1), labels)\n",
    "        \n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 218/218 [00:04<00:00, 51.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Set Accuracy: 0.7236\n",
      "\n",
      "Prediction examples:\n",
      "Sentence: it 's a charming and often affecting journey . \n",
      "True label: 1 (Positive)\n",
      "Predicted: 1 (Positive)\n",
      "Correct: True\n",
      "--------------------------------------------------\n",
      "Sentence: unflinchingly bleak and desperate \n",
      "True label: 0 (Negative)\n",
      "Predicted: 1 (Positive)\n",
      "Correct: False\n",
      "--------------------------------------------------\n",
      "Sentence: allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . \n",
      "True label: 1 (Positive)\n",
      "Predicted: 1 (Positive)\n",
      "Correct: True\n",
      "--------------------------------------------------\n",
      "Sentence: the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . \n",
      "True label: 1 (Positive)\n",
      "Predicted: 1 (Positive)\n",
      "Correct: True\n",
      "--------------------------------------------------\n",
      "Sentence: it 's slow -- very , very slow . \n",
      "True label: 0 (Negative)\n",
      "Predicted: 0 (Negative)\n",
      "Correct: True\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 評価\n",
    "classifier_model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dev_loader, desc='Evaluating'):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        logits = classifier_model(input_ids, attention_mask)\n",
    "        predictions = torch.sigmoid(logits.squeeze(-1)) > 0.5\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 精度の計算\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f'Development Set Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# いくつかの予測例を表示\n",
    "print(\"\\nPrediction examples:\")\n",
    "for i in range(5):\n",
    "    sentence = dev_df['sentence'].iloc[i]\n",
    "    true_label = dev_df['label'].iloc[i]\n",
    "    pred_label = int(all_predictions[i])\n",
    "    \n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"True label: {true_label} ({'Positive' if true_label == 1 else 'Negative'})\")\n",
    "    print(f\"Predicted: {pred_label} ({'Positive' if pred_label == 1 else 'Negative'})\")\n",
    "    print(f\"Correct: {true_label == pred_label}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "UnREZD3nTWUr",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 98. ファインチューニング\n",
    "\n",
    "問題96のプロンプトに対して、正解の感情ラベルをテキストの応答として返すように事前学習済みモデルをファインチューニングせよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama3.2-3B-InstuructをQLoRAでチューニングした場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    LlamaForCausalLM, AutoTokenizer,\n",
    "    Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model, LoraConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "\n",
    "dotenv_path = './.env'\n",
    "load_dotenv(dotenv_path)\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Current GPU Usage ===\n",
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "GPU: NVIDIA RTX A4500\n",
      "Total VRAM: 21.0 GB\n",
      "Available VRAM: 0.0 GB\n",
      "Cached VRAM: 0.0 GB\n",
      "\n",
      "GPU 0 (NVIDIA RTX A4500):\n",
      "  Allocated: 0.0 GB\n",
      "  Reserved: 0.0 GB\n",
      "  Total: 21.0 GB\n"
     ]
    }
   ],
   "source": [
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "output_dir = 'output/qlora-llama3b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Current device: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7e252ad7294bf7a7d3a6c6edfcef65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "print(device)\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current device: {current_device}\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\": current_device},\n",
    "        low_cpu_mem_usage=False\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "        inference_mode=False\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_prompt(sentence, label, tokenizer):\n",
    "    instruction = 'Determine if the sentiment of this sentence is positive or negative. Answer with only \"positive\" or \"negative\".'\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": sentence}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    response = \"positive\" if label == 1 else \"negative\"\n",
    "    full_text = prompt + response + tokenizer.eos_token\n",
    "\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer, max_length=512):\n",
    "    texts = []\n",
    "    for sentence, label in zip(examples['sentence'], examples['label']):\n",
    "        full_text = create_training_prompt(sentence, label, tokenizer)\n",
    "        texts.append(full_text)\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].clone()\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 67349\n",
      "Development samples: 872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('./data/SST-2/train.tsv', sep='\\t')\n",
    "dev_df = pd.read_csv('./data/SST-2/dev.tsv', sep='\\t')\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Development samples: {len(dev_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created successfully!\n",
      "Train dataset: Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 67349\n",
      "})\n",
      "Dev dataset: Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 872\n",
      "})\n",
      "\n",
      "First training example:\n",
      "Sentence: hide new secretions from the parental units \n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)\n",
    "\n",
    "print(\"Dataset created successfully!\")\n",
    "print(f\"Train dataset: {train_dataset}\")\n",
    "print(f\"Dev dataset: {dev_dataset}\")\n",
    "\n",
    "# データセットの内容確認\n",
    "print(f\"\\nFirst training example:\")\n",
    "print(f\"Sentence: {train_dataset[0]['sentence']}\")\n",
    "print(f\"Label: {train_dataset[0]['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f926e96f254c38a4dc61be6c6a2565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b21f78815e4f53b084596b9afaf4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed!\n",
      "Tokenized train dataset: Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 67349\n",
      "})\n",
      "Tokenized dev dataset: Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 872\n",
      "})\n",
      "\n",
      "First tokenized example:\n",
      "Input IDs length: 512\n",
      "Decoded text: <|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 04 Jun 2025\n",
      "\n",
      "Determine if the sentiment of this sentence is positive or negative. Answer with only \"positive\" or \"negative\".<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hide new secretions from the parental units<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "negative<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>...\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(\n",
    "    lambda x: preprocess_function(x, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "tokenized_dev = dev_dataset.map(\n",
    "    lambda x: preprocess_function(x, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=dev_dataset.column_names\n",
    ")\n",
    "\n",
    "print(\"Tokenization completed!\")\n",
    "print(f\"Tokenized train dataset: {tokenized_train}\")\n",
    "print(f\"Tokenized dev dataset: {tokenized_dev}\")\n",
    "\n",
    "# トークナイズされたデータの確認\n",
    "print(f\"\\nFirst tokenized example:\")\n",
    "example = tokenized_train[0]\n",
    "print(f\"Input IDs length: {len(example['input_ids'])}\")\n",
    "print(f\"Decoded text: {tokenizer.decode(example['input_ids'][:100])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collator created!\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # 因果言語モデルなのでFalse\n",
    "    pad_to_multiple_of=8,  # 効率化のため\n",
    ")\n",
    "\n",
    "print(\"Data collator created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arguments configured!\n",
      "Output directory: output/qlora-llama3b\n",
      "Batch size: 8\n",
      "Learning rate: 0.0002\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=8,  # メモリ制約に応じて調整\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=500,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,  # メモリ節約\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None,  # wandbなどの使用を無効化\n",
    "    no_cuda=False,\n",
    "    dataloader_num_workers=0,\n",
    ")\n",
    "\n",
    "print(\"Training arguments configured!\")\n",
    "print(f\"Output directory: {training_args.output_dir}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer created successfully!\n",
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8419' max='8419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8419/8419 6:21:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.002500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.636100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.627200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.624900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.602900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.583100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.558100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.548900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tosshy/workspace/2025/ch10/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning completed!\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Trainer created successfully!\")\n",
    "print(\"Starting fine-tuning...\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"Fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters:     1808.05M\n",
      "Trainable parameters: 4.59M\n"
     ]
    }
   ],
   "source": [
    "def print_model_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters:     {total/1e6:.2f}M\")\n",
    "    print(f\"Trainable parameters: {trainable/1e6:.2f}M\")\n",
    "\n",
    "print_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,587,520 || all params: 3,217,337,344 || trainable%: 0.1426\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to output/qlora-llama3b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_runtime': 84.3626, 'eval_samples_per_second': 10.336, 'eval_steps_per_second': 1.292, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011ea193ae6f416b976a0b0c353e7f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval gen:   0%|                                                                                                               | 0/872 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   0%|                                                                                                       | 1/872 [00:00<02:51,  5.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   0%|▏                                                                                                      | 2/872 [00:00<02:26,  5.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   0%|▎                                                                                                      | 3/872 [00:00<02:17,  6.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   0%|▍                                                                                                      | 4/872 [00:00<02:14,  6.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|▌                                                                                                      | 5/872 [00:00<02:13,  6.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|▋                                                                                                      | 6/872 [00:00<02:11,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|▊                                                                                                      | 7/872 [00:01<02:13,  6.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|▉                                                                                                      | 8/872 [00:01<02:11,  6.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|█                                                                                                      | 9/872 [00:01<02:09,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|█▏                                                                                                    | 10/872 [00:01<02:07,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|█▎                                                                                                    | 11/872 [00:01<02:07,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|█▍                                                                                                    | 12/872 [00:01<02:06,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|█▌                                                                                                    | 13/872 [00:01<02:05,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|█▋                                                                                                    | 14/872 [00:02<02:05,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|█▊                                                                                                    | 15/872 [00:02<02:05,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|█▊                                                                                                    | 16/872 [00:02<02:05,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|█▉                                                                                                    | 17/872 [00:02<02:05,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|██                                                                                                    | 18/872 [00:02<02:04,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|██▏                                                                                                   | 19/872 [00:02<02:06,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|██▎                                                                                                   | 20/872 [00:03<02:05,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|██▍                                                                                                   | 21/872 [00:03<02:04,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|██▌                                                                                                   | 22/872 [00:03<02:04,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|██▋                                                                                                   | 23/872 [00:03<02:04,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|██▊                                                                                                   | 24/872 [00:03<02:04,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|██▉                                                                                                   | 25/872 [00:03<02:04,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|███                                                                                                   | 26/872 [00:03<02:03,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|███▏                                                                                                  | 27/872 [00:04<02:02,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|███▎                                                                                                  | 28/872 [00:04<02:02,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|███▍                                                                                                  | 29/872 [00:04<02:03,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|███▌                                                                                                  | 30/872 [00:04<02:04,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|███▋                                                                                                  | 31/872 [00:04<02:03,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|███▋                                                                                                  | 32/872 [00:04<02:02,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|███▊                                                                                                  | 33/872 [00:04<02:04,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|███▉                                                                                                  | 34/872 [00:05<02:03,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|████                                                                                                  | 35/872 [00:05<02:03,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|████▏                                                                                                 | 36/872 [00:05<02:03,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|████▎                                                                                                 | 37/872 [00:05<02:02,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|████▍                                                                                                 | 38/872 [00:05<02:01,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|████▌                                                                                                 | 39/872 [00:05<02:01,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|████▋                                                                                                 | 40/872 [00:05<02:01,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|████▊                                                                                                 | 41/872 [00:06<02:01,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|████▉                                                                                                 | 42/872 [00:06<02:01,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|█████                                                                                                 | 43/872 [00:06<02:02,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|█████▏                                                                                                | 44/872 [00:06<02:02,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|█████▎                                                                                                | 45/872 [00:06<02:03,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|█████▍                                                                                                | 46/872 [00:06<02:02,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|█████▍                                                                                                | 47/872 [00:06<02:03,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|█████▌                                                                                                | 48/872 [00:07<02:02,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|█████▋                                                                                                | 49/872 [00:07<02:02,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|█████▊                                                                                                | 50/872 [00:07<02:02,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|█████▉                                                                                                | 51/872 [00:07<02:00,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|██████                                                                                                | 52/872 [00:07<02:00,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|██████▏                                                                                               | 53/872 [00:07<02:00,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|██████▎                                                                                               | 54/872 [00:08<02:00,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|██████▍                                                                                               | 55/872 [00:08<02:00,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|██████▌                                                                                               | 56/872 [00:08<02:00,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|██████▋                                                                                               | 57/872 [00:08<02:00,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|██████▊                                                                                               | 58/872 [00:08<02:09,  6.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|██████▉                                                                                               | 59/872 [00:08<02:07,  6.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|███████                                                                                               | 60/872 [00:08<02:03,  6.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|███████▏                                                                                              | 61/872 [00:09<02:02,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|███████▎                                                                                              | 62/872 [00:09<02:00,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|███████▎                                                                                              | 63/872 [00:09<01:59,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|███████▍                                                                                              | 64/872 [00:09<01:58,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|███████▌                                                                                              | 65/872 [00:09<01:58,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|███████▋                                                                                              | 66/872 [00:09<01:58,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|███████▊                                                                                              | 67/872 [00:09<01:58,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|███████▉                                                                                              | 68/872 [00:10<01:58,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|████████                                                                                              | 69/872 [00:10<01:58,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|████████▏                                                                                             | 70/872 [00:10<01:57,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|████████▎                                                                                             | 71/872 [00:10<01:56,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|████████▍                                                                                             | 72/872 [00:10<01:55,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|████████▌                                                                                             | 73/872 [00:10<01:56,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|████████▋                                                                                             | 74/872 [00:10<01:55,  6.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|████████▊                                                                                             | 75/872 [00:11<01:56,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|████████▉                                                                                             | 76/872 [00:11<01:56,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|█████████                                                                                             | 77/872 [00:11<01:56,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|█████████                                                                                             | 78/872 [00:11<01:56,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|█████████▏                                                                                            | 79/872 [00:11<01:55,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|█████████▎                                                                                            | 80/872 [00:11<01:55,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|█████████▍                                                                                            | 81/872 [00:11<01:55,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|█████████▌                                                                                            | 82/872 [00:12<01:55,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|█████████▋                                                                                            | 83/872 [00:12<01:55,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|█████████▊                                                                                            | 84/872 [00:12<01:54,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|█████████▉                                                                                            | 85/872 [00:12<01:55,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|██████████                                                                                            | 86/872 [00:12<01:55,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|██████████▏                                                                                           | 87/872 [00:12<01:55,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|██████████▎                                                                                           | 88/872 [00:13<01:55,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|██████████▍                                                                                           | 89/872 [00:13<01:55,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|██████████▌                                                                                           | 90/872 [00:13<01:54,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|██████████▋                                                                                           | 91/872 [00:13<01:54,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|██████████▊                                                                                           | 92/872 [00:13<01:54,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|██████████▉                                                                                           | 93/872 [00:13<01:54,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|██████████▉                                                                                           | 94/872 [00:13<01:54,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|███████████                                                                                           | 95/872 [00:14<01:52,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|███████████▏                                                                                          | 96/872 [00:14<01:52,  6.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|███████████▎                                                                                          | 97/872 [00:14<01:51,  6.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|███████████▍                                                                                          | 98/872 [00:14<01:50,  6.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|███████████▌                                                                                          | 99/872 [00:14<01:50,  6.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|███████████▌                                                                                         | 100/872 [00:14<01:52,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|███████████▋                                                                                         | 101/872 [00:14<01:52,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|███████████▊                                                                                         | 102/872 [00:15<01:53,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|███████████▉                                                                                         | 103/872 [00:15<01:53,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|████████████                                                                                         | 104/872 [00:15<01:53,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|████████████▏                                                                                        | 105/872 [00:15<01:52,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|████████████▎                                                                                        | 106/872 [00:15<01:51,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|████████████▍                                                                                        | 107/872 [00:15<01:51,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|████████████▌                                                                                        | 108/872 [00:15<01:52,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|████████████▋                                                                                        | 109/872 [00:16<01:52,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|████████████▋                                                                                        | 110/872 [00:16<01:52,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|████████████▊                                                                                        | 111/872 [00:16<01:52,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|████████████▉                                                                                        | 112/872 [00:16<01:52,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|█████████████                                                                                        | 113/872 [00:16<01:52,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|█████████████▏                                                                                       | 114/872 [00:16<01:53,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|█████████████▎                                                                                       | 115/872 [00:16<01:51,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|█████████████▍                                                                                       | 116/872 [00:17<01:51,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|█████████████▌                                                                                       | 117/872 [00:17<01:52,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|█████████████▋                                                                                       | 118/872 [00:17<01:50,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|█████████████▊                                                                                       | 119/872 [00:17<01:50,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|█████████████▉                                                                                       | 120/872 [00:17<01:50,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|██████████████                                                                                       | 121/872 [00:17<01:49,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|██████████████▏                                                                                      | 122/872 [00:18<01:49,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|██████████████▏                                                                                      | 123/872 [00:18<01:50,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|██████████████▎                                                                                      | 124/872 [00:18<01:50,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|██████████████▍                                                                                      | 125/872 [00:18<01:41,  7.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|██████████████▌                                                                                      | 126/872 [00:18<01:44,  7.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|██████████████▋                                                                                      | 127/872 [00:18<01:44,  7.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|██████████████▊                                                                                      | 128/872 [00:18<01:46,  6.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|██████████████▉                                                                                      | 129/872 [00:18<01:46,  7.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|███████████████                                                                                      | 130/872 [00:19<01:46,  6.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|███████████████▏                                                                                     | 131/872 [00:19<01:47,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|███████████████▎                                                                                     | 132/872 [00:19<01:48,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|███████████████▍                                                                                     | 133/872 [00:19<01:48,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|███████████████▌                                                                                     | 134/872 [00:19<01:47,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|███████████████▋                                                                                     | 135/872 [00:19<01:47,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|███████████████▊                                                                                     | 136/872 [00:20<01:47,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|███████████████▊                                                                                     | 137/872 [00:20<01:47,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|███████████████▉                                                                                     | 138/872 [00:20<01:47,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|████████████████                                                                                     | 139/872 [00:20<01:48,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|████████████████▏                                                                                    | 140/872 [00:20<01:48,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|████████████████▎                                                                                    | 141/872 [00:20<01:48,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|████████████████▍                                                                                    | 142/872 [00:20<01:49,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|████████████████▌                                                                                    | 143/872 [00:21<01:48,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|████████████████▋                                                                                    | 144/872 [00:21<01:48,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|████████████████▊                                                                                    | 145/872 [00:21<01:47,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|████████████████▉                                                                                    | 146/872 [00:21<01:46,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|█████████████████                                                                                    | 147/872 [00:21<01:46,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|█████████████████▏                                                                                   | 148/872 [00:21<01:45,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|█████████████████▎                                                                                   | 149/872 [00:21<01:45,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|█████████████████▎                                                                                   | 150/872 [00:22<01:44,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|█████████████████▍                                                                                   | 151/872 [00:22<01:45,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|█████████████████▌                                                                                   | 152/872 [00:22<01:45,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|█████████████████▋                                                                                   | 153/872 [00:22<01:44,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|█████████████████▊                                                                                   | 154/872 [00:22<01:45,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|█████████████████▉                                                                                   | 155/872 [00:22<01:45,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|██████████████████                                                                                   | 156/872 [00:22<01:44,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|██████████████████▏                                                                                  | 157/872 [00:23<01:45,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|██████████████████▎                                                                                  | 158/872 [00:23<01:44,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|██████████████████▍                                                                                  | 159/872 [00:23<01:43,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|██████████████████▌                                                                                  | 160/872 [00:23<01:44,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|██████████████████▋                                                                                  | 161/872 [00:23<01:43,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|██████████████████▊                                                                                  | 162/872 [00:23<01:39,  7.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|██████████████████▉                                                                                  | 163/872 [00:23<01:39,  7.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|██████████████████▉                                                                                  | 164/872 [00:24<01:40,  7.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|███████████████████                                                                                  | 165/872 [00:24<01:41,  6.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|███████████████████▏                                                                                 | 166/872 [00:24<01:42,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|███████████████████▎                                                                                 | 167/872 [00:24<01:41,  6.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|███████████████████▍                                                                                 | 168/872 [00:24<01:42,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|███████████████████▌                                                                                 | 169/872 [00:24<01:42,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|███████████████████▋                                                                                 | 170/872 [00:24<01:43,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|███████████████████▊                                                                                 | 171/872 [00:25<01:43,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|███████████████████▉                                                                                 | 172/872 [00:25<01:43,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|████████████████████                                                                                 | 173/872 [00:25<01:43,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|████████████████████▏                                                                                | 174/872 [00:25<01:44,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|████████████████████▎                                                                                | 175/872 [00:25<01:43,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|████████████████████▍                                                                                | 176/872 [00:25<01:43,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|████████████████████▌                                                                                | 177/872 [00:26<01:43,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|████████████████████▌                                                                                | 178/872 [00:26<01:41,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|████████████████████▋                                                                                | 179/872 [00:26<01:49,  6.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|████████████████████▊                                                                                | 180/872 [00:26<01:47,  6.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|████████████████████▉                                                                                | 181/872 [00:26<01:45,  6.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|█████████████████████                                                                                | 182/872 [00:26<01:44,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|█████████████████████▏                                                                               | 183/872 [00:26<01:42,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|█████████████████████▎                                                                               | 184/872 [00:27<01:42,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|█████████████████████▍                                                                               | 185/872 [00:27<01:41,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|█████████████████████▌                                                                               | 186/872 [00:27<01:41,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|█████████████████████▋                                                                               | 187/872 [00:27<01:41,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|█████████████████████▊                                                                               | 188/872 [00:27<01:41,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|█████████████████████▉                                                                               | 189/872 [00:27<01:41,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|██████████████████████                                                                               | 190/872 [00:27<01:39,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|██████████████████████                                                                               | 191/872 [00:28<01:38,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|██████████████████████▏                                                                              | 192/872 [00:28<01:38,  6.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|██████████████████████▎                                                                              | 193/872 [00:28<01:37,  6.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|██████████████████████▍                                                                              | 194/872 [00:28<01:37,  6.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|██████████████████████▌                                                                              | 195/872 [00:28<01:36,  7.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|██████████████████████▋                                                                              | 196/872 [00:28<01:37,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|██████████████████████▊                                                                              | 197/872 [00:28<01:38,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|██████████████████████▉                                                                              | 198/872 [00:29<01:39,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|███████████████████████                                                                              | 199/872 [00:29<01:38,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|███████████████████████▏                                                                             | 200/872 [00:29<01:37,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|███████████████████████▎                                                                             | 201/872 [00:29<01:37,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|███████████████████████▍                                                                             | 202/872 [00:29<01:37,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|███████████████████████▌                                                                             | 203/872 [00:29<01:38,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|███████████████████████▋                                                                             | 204/872 [00:29<01:33,  7.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|███████████████████████▋                                                                             | 205/872 [00:30<01:34,  7.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|███████████████████████▊                                                                             | 206/872 [00:30<01:35,  6.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|███████████████████████▉                                                                             | 207/872 [00:30<01:36,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|████████████████████████                                                                             | 208/872 [00:30<01:36,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|████████████████████████▏                                                                            | 209/872 [00:30<01:37,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|████████████████████████▎                                                                            | 210/872 [00:30<01:36,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|████████████████████████▍                                                                            | 211/872 [00:31<01:36,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|████████████████████████▌                                                                            | 212/872 [00:31<01:36,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|████████████████████████▋                                                                            | 213/872 [00:31<01:36,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|████████████████████████▊                                                                            | 214/872 [00:31<01:35,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|████████████████████████▉                                                                            | 215/872 [00:31<01:35,  6.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|█████████████████████████                                                                            | 216/872 [00:31<01:34,  6.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|█████████████████████████▏                                                                           | 217/872 [00:31<01:34,  6.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|█████████████████████████▎                                                                           | 218/872 [00:32<01:34,  6.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|█████████████████████████▎                                                                           | 219/872 [00:32<01:35,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|█████████████████████████▍                                                                           | 220/872 [00:32<01:34,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|█████████████████████████▌                                                                           | 221/872 [00:32<01:33,  6.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|█████████████████████████▋                                                                           | 222/872 [00:32<01:41,  6.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|█████████████████████████▊                                                                           | 223/872 [00:32<01:38,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|█████████████████████████▉                                                                           | 224/872 [00:32<01:37,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|██████████████████████████                                                                           | 225/872 [00:33<01:36,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|██████████████████████████▏                                                                          | 226/872 [00:33<01:36,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|██████████████████████████▎                                                                          | 227/872 [00:33<01:36,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|██████████████████████████▍                                                                          | 228/872 [00:33<01:35,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|██████████████████████████▌                                                                          | 229/872 [00:33<01:35,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|██████████████████████████▋                                                                          | 230/872 [00:33<01:42,  6.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|██████████████████████████▊                                                                          | 231/872 [00:34<01:40,  6.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|██████████████████████████▊                                                                          | 232/872 [00:34<01:37,  6.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|██████████████████████████▉                                                                          | 233/872 [00:34<01:36,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|███████████████████████████                                                                          | 234/872 [00:34<01:35,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|███████████████████████████▏                                                                         | 235/872 [00:34<01:35,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|███████████████████████████▎                                                                         | 236/872 [00:34<01:34,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|███████████████████████████▍                                                                         | 237/872 [00:34<01:33,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|███████████████████████████▌                                                                         | 238/872 [00:35<01:33,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|███████████████████████████▋                                                                         | 239/872 [00:35<01:33,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|███████████████████████████▊                                                                         | 240/872 [00:35<01:33,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|███████████████████████████▉                                                                         | 241/872 [00:35<01:33,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|████████████████████████████                                                                         | 242/872 [00:35<01:33,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|████████████████████████████▏                                                                        | 243/872 [00:35<01:33,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|████████████████████████████▎                                                                        | 244/872 [00:35<01:33,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|████████████████████████████▍                                                                        | 245/872 [00:36<01:32,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|████████████████████████████▍                                                                        | 246/872 [00:36<01:31,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|████████████████████████████▌                                                                        | 247/872 [00:36<01:30,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|████████████████████████████▋                                                                        | 248/872 [00:36<01:30,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|████████████████████████████▊                                                                        | 249/872 [00:36<01:31,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|████████████████████████████▉                                                                        | 250/872 [00:36<01:31,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|█████████████████████████████                                                                        | 251/872 [00:36<01:31,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|█████████████████████████████▏                                                                       | 252/872 [00:37<01:31,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|█████████████████████████████▎                                                                       | 253/872 [00:37<01:32,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|█████████████████████████████▍                                                                       | 254/872 [00:37<01:30,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|█████████████████████████████▌                                                                       | 255/872 [00:37<01:30,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|█████████████████████████████▋                                                                       | 256/872 [00:37<01:31,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|█████████████████████████████▊                                                                       | 257/872 [00:37<01:31,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|█████████████████████████████▉                                                                       | 258/872 [00:37<01:31,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|█████████████████████████████▉                                                                       | 259/872 [00:38<01:31,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|██████████████████████████████                                                                       | 260/872 [00:38<01:29,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|██████████████████████████████▏                                                                      | 261/872 [00:38<01:29,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|██████████████████████████████▎                                                                      | 262/872 [00:38<01:29,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|██████████████████████████████▍                                                                      | 263/872 [00:38<01:28,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|██████████████████████████████▌                                                                      | 264/872 [00:38<01:29,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|██████████████████████████████▋                                                                      | 265/872 [00:39<01:29,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|██████████████████████████████▊                                                                      | 266/872 [00:39<01:28,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|██████████████████████████████▉                                                                      | 267/872 [00:39<01:22,  7.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|███████████████████████████████                                                                      | 268/872 [00:39<01:24,  7.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|███████████████████████████████▏                                                                     | 269/872 [00:39<01:25,  7.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|███████████████████████████████▎                                                                     | 270/872 [00:39<01:26,  6.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|███████████████████████████████▍                                                                     | 271/872 [00:39<01:27,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|███████████████████████████████▌                                                                     | 272/872 [00:40<01:27,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|███████████████████████████████▌                                                                     | 273/872 [00:40<01:28,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|███████████████████████████████▋                                                                     | 274/872 [00:40<01:28,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|███████████████████████████████▊                                                                     | 275/872 [00:40<01:27,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|███████████████████████████████▉                                                                     | 276/872 [00:40<01:27,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|████████████████████████████████                                                                     | 277/872 [00:40<01:26,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|████████████████████████████████▏                                                                    | 278/872 [00:40<01:26,  6.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|████████████████████████████████▎                                                                    | 279/872 [00:41<01:26,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|████████████████████████████████▍                                                                    | 280/872 [00:41<01:27,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|████████████████████████████████▌                                                                    | 281/872 [00:41<01:26,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|████████████████████████████████▋                                                                    | 282/872 [00:41<01:27,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|████████████████████████████████▊                                                                    | 283/872 [00:41<01:26,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|████████████████████████████████▉                                                                    | 284/872 [00:41<01:26,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████                                                                    | 285/872 [00:41<01:26,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████▏                                                                   | 286/872 [00:42<01:26,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████▏                                                                   | 287/872 [00:42<01:26,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████▎                                                                   | 288/872 [00:42<01:26,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████▍                                                                   | 289/872 [00:42<01:25,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████▌                                                                   | 290/872 [00:42<01:21,  7.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████▋                                                                   | 291/872 [00:42<01:22,  7.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████▊                                                                   | 292/872 [00:42<01:22,  6.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|█████████████████████████████████▉                                                                   | 293/872 [00:43<01:22,  6.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████                                                                   | 294/872 [00:43<01:23,  6.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████▏                                                                  | 295/872 [00:43<01:23,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████▎                                                                  | 296/872 [00:43<01:24,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████▍                                                                  | 297/872 [00:43<01:23,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████▌                                                                  | 298/872 [00:43<01:24,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████▋                                                                  | 299/872 [00:43<01:24,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████▋                                                                  | 300/872 [00:44<01:24,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|██████████████████████████████████▊                                                                  | 301/872 [00:44<01:25,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|██████████████████████████████████▉                                                                  | 302/872 [00:44<01:24,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|███████████████████████████████████                                                                  | 303/872 [00:44<01:24,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|███████████████████████████████████▏                                                                 | 304/872 [00:44<01:24,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|███████████████████████████████████▎                                                                 | 305/872 [00:44<01:23,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|███████████████████████████████████▍                                                                 | 306/872 [00:44<01:23,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|███████████████████████████████████▌                                                                 | 307/872 [00:45<01:23,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|███████████████████████████████████▋                                                                 | 308/872 [00:45<01:24,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|███████████████████████████████████▊                                                                 | 309/872 [00:45<01:23,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|███████████████████████████████████▉                                                                 | 310/872 [00:45<01:23,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|████████████████████████████████████                                                                 | 311/872 [00:45<01:23,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|████████████████████████████████████▏                                                                | 312/872 [00:45<01:23,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|████████████████████████████████████▎                                                                | 313/872 [00:46<01:23,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|████████████████████████████████████▎                                                                | 314/872 [00:46<01:23,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|████████████████████████████████████▍                                                                | 315/872 [00:46<01:23,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|████████████████████████████████████▌                                                                | 316/872 [00:46<01:23,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|████████████████████████████████████▋                                                                | 317/872 [00:46<01:23,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|████████████████████████████████████▊                                                                | 318/872 [00:46<01:22,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|████████████████████████████████████▉                                                                | 319/872 [00:46<01:21,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|█████████████████████████████████████                                                                | 320/872 [00:47<01:27,  6.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|█████████████████████████████████████▏                                                               | 321/872 [00:47<01:26,  6.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|█████████████████████████████████████▎                                                               | 322/872 [00:47<01:25,  6.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|█████████████████████████████████████▍                                                               | 323/872 [00:47<01:24,  6.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|█████████████████████████████████████▌                                                               | 324/872 [00:47<01:23,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|█████████████████████████████████████▋                                                               | 325/872 [00:47<01:16,  7.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|█████████████████████████████████████▊                                                               | 326/872 [00:47<01:18,  6.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|█████████████████████████████████████▉                                                               | 327/872 [00:48<01:18,  6.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|█████████████████████████████████████▉                                                               | 328/872 [00:48<01:19,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|██████████████████████████████████████                                                               | 329/872 [00:48<01:20,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|██████████████████████████████████████▏                                                              | 330/872 [00:48<01:20,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|██████████████████████████████████████▎                                                              | 331/872 [00:48<01:20,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|██████████████████████████████████████▍                                                              | 332/872 [00:48<01:20,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|██████████████████████████████████████▌                                                              | 333/872 [00:49<01:20,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|██████████████████████████████████████▋                                                              | 334/872 [00:49<01:19,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|██████████████████████████████████████▊                                                              | 335/872 [00:49<01:19,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|██████████████████████████████████████▉                                                              | 336/872 [00:49<01:18,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████                                                              | 337/872 [00:49<01:18,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████▏                                                             | 338/872 [00:49<01:18,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████▎                                                             | 339/872 [00:49<01:17,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████▍                                                             | 340/872 [00:50<01:18,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████▍                                                             | 341/872 [00:50<01:17,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████▌                                                             | 342/872 [00:50<01:18,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████▋                                                             | 343/872 [00:50<01:18,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████▊                                                             | 344/872 [00:50<01:18,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|███████████████████████████████████████▉                                                             | 345/872 [00:50<01:18,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|████████████████████████████████████████                                                             | 346/872 [00:50<01:17,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|████████████████████████████████████████▏                                                            | 347/872 [00:51<01:17,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|████████████████████████████████████████▎                                                            | 348/872 [00:51<01:17,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|████████████████████████████████████████▍                                                            | 349/872 [00:51<01:18,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|████████████████████████████████████████▌                                                            | 350/872 [00:51<01:17,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|████████████████████████████████████████▋                                                            | 351/872 [00:51<01:16,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|████████████████████████████████████████▊                                                            | 352/872 [00:51<01:16,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|████████████████████████████████████████▉                                                            | 353/872 [00:51<01:16,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████                                                            | 354/872 [00:52<01:16,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████                                                            | 355/872 [00:52<01:16,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████▏                                                           | 356/872 [00:52<01:16,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████▎                                                           | 357/872 [00:52<01:16,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████▍                                                           | 358/872 [00:52<01:16,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████▌                                                           | 359/872 [00:52<01:10,  7.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████▋                                                           | 360/872 [00:52<01:12,  7.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████▊                                                           | 361/872 [00:53<01:13,  6.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|█████████████████████████████████████████▉                                                           | 362/872 [00:53<01:14,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████                                                           | 363/872 [00:53<01:14,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████▏                                                          | 364/872 [00:53<01:15,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████▎                                                          | 365/872 [00:53<01:15,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████▍                                                          | 366/872 [00:53<01:15,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████▌                                                          | 367/872 [00:54<01:15,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████▌                                                          | 368/872 [00:54<01:14,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████▋                                                          | 369/872 [00:54<01:15,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████▊                                                          | 370/872 [00:54<01:13,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|██████████████████████████████████████████▉                                                          | 371/872 [00:54<01:13,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████                                                          | 372/872 [00:54<01:13,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████▏                                                         | 373/872 [00:54<01:12,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████▎                                                         | 374/872 [00:55<01:13,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████▍                                                         | 375/872 [00:55<01:13,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████▌                                                         | 376/872 [00:55<01:13,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████▋                                                         | 377/872 [00:55<01:13,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████▊                                                         | 378/872 [00:55<01:13,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████▉                                                         | 379/872 [00:55<01:12,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████                                                         | 380/872 [00:55<01:12,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████▏                                                        | 381/872 [00:56<01:12,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████▏                                                        | 382/872 [00:56<01:12,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████▎                                                        | 383/872 [00:56<01:12,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████▍                                                        | 384/872 [00:56<01:12,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████▌                                                        | 385/872 [00:56<01:12,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████▋                                                        | 386/872 [00:56<01:11,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████▊                                                        | 387/872 [00:56<01:11,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|████████████████████████████████████████████▉                                                        | 388/872 [00:57<01:11,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|█████████████████████████████████████████████                                                        | 389/872 [00:57<01:11,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|█████████████████████████████████████████████▏                                                       | 390/872 [00:57<01:12,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|█████████████████████████████████████████████▎                                                       | 391/872 [00:57<01:11,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|█████████████████████████████████████████████▍                                                       | 392/872 [00:57<01:11,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|█████████████████████████████████████████████▌                                                       | 393/872 [00:57<01:11,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|█████████████████████████████████████████████▋                                                       | 394/872 [00:58<01:11,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|█████████████████████████████████████████████▊                                                       | 395/872 [00:58<01:10,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|█████████████████████████████████████████████▊                                                       | 396/872 [00:58<01:10,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|█████████████████████████████████████████████▉                                                       | 397/872 [00:58<01:10,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████                                                       | 398/872 [00:58<01:10,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████▏                                                      | 399/872 [00:58<01:11,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████▎                                                      | 400/872 [00:58<01:10,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████▍                                                      | 401/872 [00:59<01:10,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████▌                                                      | 402/872 [00:59<01:04,  7.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████▋                                                      | 403/872 [00:59<01:06,  7.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████▊                                                      | 404/872 [00:59<01:08,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████▉                                                      | 405/872 [00:59<01:08,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████                                                      | 406/872 [00:59<01:03,  7.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████▏                                                     | 407/872 [00:59<01:04,  7.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████▎                                                     | 408/872 [01:00<01:06,  7.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████▎                                                     | 409/872 [01:00<01:06,  6.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████▍                                                     | 410/872 [01:00<01:07,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████▌                                                     | 411/872 [01:00<01:06,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████▋                                                     | 412/872 [01:00<01:02,  7.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████▊                                                     | 413/872 [01:00<01:04,  7.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████▉                                                     | 414/872 [01:00<01:05,  6.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|████████████████████████████████████████████████                                                     | 415/872 [01:01<01:06,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|████████████████████████████████████████████████▏                                                    | 416/872 [01:01<01:06,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|████████████████████████████████████████████████▎                                                    | 417/872 [01:01<01:06,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|████████████████████████████████████████████████▍                                                    | 418/872 [01:01<01:07,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|████████████████████████████████████████████████▌                                                    | 419/872 [01:01<01:07,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|████████████████████████████████████████████████▋                                                    | 420/872 [01:01<01:13,  6.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|████████████████████████████████████████████████▊                                                    | 421/872 [01:02<01:11,  6.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|████████████████████████████████████████████████▉                                                    | 422/872 [01:02<01:10,  6.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|████████████████████████████████████████████████▉                                                    | 423/872 [01:02<01:08,  6.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|█████████████████████████████████████████████████                                                    | 424/872 [01:02<01:07,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|█████████████████████████████████████████████████▏                                                   | 425/872 [01:02<01:07,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|█████████████████████████████████████████████████▎                                                   | 426/872 [01:02<01:07,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|█████████████████████████████████████████████████▍                                                   | 427/872 [01:02<01:02,  7.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|█████████████████████████████████████████████████▌                                                   | 428/872 [01:03<01:02,  7.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|█████████████████████████████████████████████████▋                                                   | 429/872 [01:03<01:03,  6.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|█████████████████████████████████████████████████▊                                                   | 430/872 [01:03<01:04,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|█████████████████████████████████████████████████▉                                                   | 431/872 [01:03<01:04,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████                                                   | 432/872 [01:03<01:05,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████▏                                                  | 433/872 [01:03<01:05,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████▎                                                  | 434/872 [01:03<01:04,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████▍                                                  | 435/872 [01:04<01:04,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████▌                                                  | 436/872 [01:04<01:04,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████▌                                                  | 437/872 [01:04<01:04,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████▋                                                  | 438/872 [01:04<01:03,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████▊                                                  | 439/872 [01:04<01:03,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████▉                                                  | 440/872 [01:04<01:04,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████                                                  | 441/872 [01:04<00:59,  7.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████▏                                                 | 442/872 [01:05<01:00,  7.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████▎                                                 | 443/872 [01:05<01:01,  6.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████▍                                                 | 444/872 [01:05<01:02,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████▌                                                 | 445/872 [01:05<01:02,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████▋                                                 | 446/872 [01:05<01:03,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████▊                                                 | 447/872 [01:05<01:02,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████▉                                                 | 448/872 [01:05<01:02,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|████████████████████████████████████████████████████                                                 | 449/872 [01:06<01:02,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|████████████████████████████████████████████████████                                                 | 450/872 [01:06<01:04,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|████████████████████████████████████████████████████▏                                                | 451/872 [01:06<01:03,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|████████████████████████████████████████████████████▎                                                | 452/872 [01:06<01:02,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|████████████████████████████████████████████████████▍                                                | 453/872 [01:06<01:01,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|████████████████████████████████████████████████████▌                                                | 454/872 [01:06<01:01,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|████████████████████████████████████████████████████▋                                                | 455/872 [01:06<01:02,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|████████████████████████████████████████████████████▊                                                | 456/872 [01:07<01:01,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|████████████████████████████████████████████████████▉                                                | 457/872 [01:07<01:01,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████                                                | 458/872 [01:07<01:01,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████▏                                               | 459/872 [01:07<00:56,  7.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████▎                                               | 460/872 [01:07<00:57,  7.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████▍                                               | 461/872 [01:07<00:58,  7.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████▌                                               | 462/872 [01:07<00:59,  6.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████▋                                               | 463/872 [01:08<00:56,  7.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████▋                                               | 464/872 [01:08<00:58,  7.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████▊                                               | 465/872 [01:08<00:58,  6.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|█████████████████████████████████████████████████████▉                                               | 466/872 [01:08<00:58,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████                                               | 467/872 [01:08<00:58,  6.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████▏                                              | 468/872 [01:08<00:58,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████▎                                              | 469/872 [01:08<00:58,  6.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████▍                                              | 470/872 [01:09<00:59,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████▌                                              | 471/872 [01:09<00:59,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████▋                                              | 472/872 [01:09<00:59,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████▊                                              | 473/872 [01:09<00:58,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████▉                                              | 474/872 [01:09<00:58,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|███████████████████████████████████████████████████████                                              | 475/872 [01:09<00:58,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████▏                                             | 476/872 [01:10<00:58,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████▏                                             | 477/872 [01:10<00:58,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████▎                                             | 478/872 [01:10<00:58,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████▍                                             | 479/872 [01:10<00:58,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████▌                                             | 480/872 [01:10<00:58,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████▋                                             | 481/872 [01:10<00:57,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████▊                                             | 482/872 [01:10<00:57,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████▉                                             | 483/872 [01:11<00:57,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████                                             | 484/872 [01:11<00:57,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████▏                                            | 485/872 [01:11<00:57,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████▎                                            | 486/872 [01:11<00:57,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████▍                                            | 487/872 [01:11<00:58,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████▌                                            | 488/872 [01:11<00:57,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████▋                                            | 489/872 [01:11<00:56,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████▊                                            | 490/872 [01:12<00:56,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████▊                                            | 491/872 [01:12<00:56,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|████████████████████████████████████████████████████████▉                                            | 492/872 [01:12<00:56,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|█████████████████████████████████████████████████████████                                            | 493/872 [01:12<00:56,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|█████████████████████████████████████████████████████████▏                                           | 494/872 [01:12<00:53,  7.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|█████████████████████████████████████████████████████████▎                                           | 495/872 [01:12<00:54,  6.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|█████████████████████████████████████████████████████████▍                                           | 496/872 [01:12<00:50,  7.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|█████████████████████████████████████████████████████████▌                                           | 497/872 [01:13<00:52,  7.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|█████████████████████████████████████████████████████████▋                                           | 498/872 [01:13<00:54,  6.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|█████████████████████████████████████████████████████████▊                                           | 499/872 [01:13<00:54,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|█████████████████████████████████████████████████████████▉                                           | 500/872 [01:13<00:54,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|██████████████████████████████████████████████████████████                                           | 501/872 [01:13<00:55,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|██████████████████████████████████████████████████████████▏                                          | 502/872 [01:13<00:55,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|██████████████████████████████████████████████████████████▎                                          | 503/872 [01:14<00:54,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|██████████████████████████████████████████████████████████▍                                          | 504/872 [01:14<00:54,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|██████████████████████████████████████████████████████████▍                                          | 505/872 [01:14<00:54,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|██████████████████████████████████████████████████████████▌                                          | 506/872 [01:14<00:54,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|██████████████████████████████████████████████████████████▋                                          | 507/872 [01:14<00:54,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|██████████████████████████████████████████████████████████▊                                          | 508/872 [01:14<00:54,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|██████████████████████████████████████████████████████████▉                                          | 509/872 [01:14<00:54,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|███████████████████████████████████████████████████████████                                          | 510/872 [01:15<00:54,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████▏                                         | 511/872 [01:15<00:54,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████▎                                         | 512/872 [01:15<00:53,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████▍                                         | 513/872 [01:15<00:53,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████▌                                         | 514/872 [01:15<00:52,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████▋                                         | 515/872 [01:15<00:52,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████▊                                         | 516/872 [01:15<00:52,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████▉                                         | 517/872 [01:16<00:52,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████▉                                         | 518/872 [01:16<00:52,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|████████████████████████████████████████████████████████████                                         | 519/872 [01:16<00:52,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|████████████████████████████████████████████████████████████▏                                        | 520/872 [01:16<00:52,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|████████████████████████████████████████████████████████████▎                                        | 521/872 [01:16<00:52,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|████████████████████████████████████████████████████████████▍                                        | 522/872 [01:16<00:52,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|████████████████████████████████████████████████████████████▌                                        | 523/872 [01:16<00:52,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|████████████████████████████████████████████████████████████▋                                        | 524/872 [01:17<00:52,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|████████████████████████████████████████████████████████████▊                                        | 525/872 [01:17<00:51,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|████████████████████████████████████████████████████████████▉                                        | 526/872 [01:17<00:51,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|█████████████████████████████████████████████████████████████                                        | 527/872 [01:17<00:51,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|█████████████████████████████████████████████████████████████▏                                       | 528/872 [01:17<00:52,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|█████████████████████████████████████████████████████████████▎                                       | 529/872 [01:17<00:51,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|█████████████████████████████████████████████████████████████▍                                       | 530/872 [01:18<00:51,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|█████████████████████████████████████████████████████████████▌                                       | 531/872 [01:18<00:50,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|█████████████████████████████████████████████████████████████▌                                       | 532/872 [01:18<00:50,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|█████████████████████████████████████████████████████████████▋                                       | 533/872 [01:18<00:49,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|█████████████████████████████████████████████████████████████▊                                       | 534/872 [01:18<00:49,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|█████████████████████████████████████████████████████████████▉                                       | 535/872 [01:18<00:49,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|██████████████████████████████████████████████████████████████                                       | 536/872 [01:18<00:49,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|██████████████████████████████████████████████████████████████▏                                      | 537/872 [01:19<00:49,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|██████████████████████████████████████████████████████████████▎                                      | 538/872 [01:19<00:49,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|██████████████████████████████████████████████████████████████▍                                      | 539/872 [01:19<00:50,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|██████████████████████████████████████████████████████████████▌                                      | 540/872 [01:19<00:50,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|██████████████████████████████████████████████████████████████▋                                      | 541/872 [01:19<00:49,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|██████████████████████████████████████████████████████████████▊                                      | 542/872 [01:19<00:49,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|██████████████████████████████████████████████████████████████▉                                      | 543/872 [01:19<00:49,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|███████████████████████████████████████████████████████████████                                      | 544/872 [01:20<00:49,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|███████████████████████████████████████████████████████████████▏                                     | 545/872 [01:20<00:49,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|███████████████████████████████████████████████████████████████▏                                     | 546/872 [01:20<00:48,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|███████████████████████████████████████████████████████████████▎                                     | 547/872 [01:20<00:48,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|███████████████████████████████████████████████████████████████▍                                     | 548/872 [01:20<00:47,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|███████████████████████████████████████████████████████████████▌                                     | 549/872 [01:20<00:48,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|███████████████████████████████████████████████████████████████▋                                     | 550/872 [01:21<00:48,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|███████████████████████████████████████████████████████████████▊                                     | 551/872 [01:21<00:47,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|███████████████████████████████████████████████████████████████▉                                     | 552/872 [01:21<00:47,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|████████████████████████████████████████████████████████████████                                     | 553/872 [01:21<00:48,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████▏                                    | 554/872 [01:21<00:44,  7.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████▎                                    | 555/872 [01:21<00:45,  6.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████▍                                    | 556/872 [01:21<00:45,  6.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████▌                                    | 557/872 [01:22<00:46,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████▋                                    | 558/872 [01:22<00:46,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████▋                                    | 559/872 [01:22<00:46,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████▊                                    | 560/872 [01:22<00:46,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████▉                                    | 561/872 [01:22<00:46,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|█████████████████████████████████████████████████████████████████                                    | 562/872 [01:22<00:42,  7.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|█████████████████████████████████████████████████████████████████▏                                   | 563/872 [01:22<00:43,  7.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|█████████████████████████████████████████████████████████████████▎                                   | 564/872 [01:23<00:44,  6.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|█████████████████████████████████████████████████████████████████▍                                   | 565/872 [01:23<00:44,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|█████████████████████████████████████████████████████████████████▌                                   | 566/872 [01:23<00:44,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|█████████████████████████████████████████████████████████████████▋                                   | 567/872 [01:23<00:45,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|█████████████████████████████████████████████████████████████████▊                                   | 568/872 [01:23<00:44,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|█████████████████████████████████████████████████████████████████▉                                   | 569/872 [01:23<00:44,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|██████████████████████████████████████████████████████████████████                                   | 570/872 [01:23<00:44,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|██████████████████████████████████████████████████████████████████▏                                  | 571/872 [01:24<00:44,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|██████████████████████████████████████████████████████████████████▎                                  | 572/872 [01:24<00:44,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|██████████████████████████████████████████████████████████████████▎                                  | 573/872 [01:24<00:44,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|██████████████████████████████████████████████████████████████████▍                                  | 574/872 [01:24<00:42,  7.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|██████████████████████████████████████████████████████████████████▌                                  | 575/872 [01:24<00:42,  6.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|██████████████████████████████████████████████████████████████████▋                                  | 576/872 [01:24<00:42,  6.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|██████████████████████████████████████████████████████████████████▊                                  | 577/872 [01:24<00:43,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|██████████████████████████████████████████████████████████████████▉                                  | 578/872 [01:25<00:43,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|███████████████████████████████████████████████████████████████████                                  | 579/872 [01:25<00:41,  7.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████▏                                 | 580/872 [01:25<00:42,  6.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████▎                                 | 581/872 [01:25<00:41,  6.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████▍                                 | 582/872 [01:25<00:42,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████▌                                 | 583/872 [01:25<00:42,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████▋                                 | 584/872 [01:25<00:42,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████▊                                 | 585/872 [01:26<00:42,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████▊                                 | 586/872 [01:26<00:42,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████▉                                 | 587/872 [01:26<00:42,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|████████████████████████████████████████████████████████████████████                                 | 588/872 [01:26<00:42,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|████████████████████████████████████████████████████████████████████▏                                | 589/872 [01:26<00:41,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|████████████████████████████████████████████████████████████████████▎                                | 590/872 [01:26<00:41,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|████████████████████████████████████████████████████████████████████▍                                | 591/872 [01:27<00:42,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|████████████████████████████████████████████████████████████████████▌                                | 592/872 [01:27<00:42,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|████████████████████████████████████████████████████████████████████▋                                | 593/872 [01:27<00:41,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|████████████████████████████████████████████████████████████████████▊                                | 594/872 [01:27<00:41,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|████████████████████████████████████████████████████████████████████▉                                | 595/872 [01:27<00:41,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|█████████████████████████████████████████████████████████████████████                                | 596/872 [01:27<00:41,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|█████████████████████████████████████████████████████████████████████▏                               | 597/872 [01:27<00:41,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|█████████████████████████████████████████████████████████████████████▎                               | 598/872 [01:28<00:40,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|█████████████████████████████████████████████████████████████████████▍                               | 599/872 [01:28<00:40,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|█████████████████████████████████████████████████████████████████████▍                               | 600/872 [01:28<00:40,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|█████████████████████████████████████████████████████████████████████▌                               | 601/872 [01:28<00:40,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|█████████████████████████████████████████████████████████████████████▋                               | 602/872 [01:28<00:40,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|█████████████████████████████████████████████████████████████████████▊                               | 603/872 [01:28<00:40,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|█████████████████████████████████████████████████████████████████████▉                               | 604/872 [01:28<00:40,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|██████████████████████████████████████████████████████████████████████                               | 605/872 [01:29<00:39,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|██████████████████████████████████████████████████████████████████████▏                              | 606/872 [01:29<00:39,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|██████████████████████████████████████████████████████████████████████▎                              | 607/872 [01:29<00:39,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|██████████████████████████████████████████████████████████████████████▍                              | 608/872 [01:29<00:39,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|██████████████████████████████████████████████████████████████████████▌                              | 609/872 [01:29<00:39,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|██████████████████████████████████████████████████████████████████████▋                              | 610/872 [01:29<00:38,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|██████████████████████████████████████████████████████████████████████▊                              | 611/872 [01:30<00:38,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|██████████████████████████████████████████████████████████████████████▉                              | 612/872 [01:30<00:39,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|███████████████████████████████████████████████████████████████████████                              | 613/872 [01:30<00:38,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|███████████████████████████████████████████████████████████████████████                              | 614/872 [01:30<00:38,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|███████████████████████████████████████████████████████████████████████▏                             | 615/872 [01:30<00:38,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|███████████████████████████████████████████████████████████████████████▎                             | 616/872 [01:30<00:38,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|███████████████████████████████████████████████████████████████████████▍                             | 617/872 [01:30<00:37,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|███████████████████████████████████████████████████████████████████████▌                             | 618/872 [01:31<00:37,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|███████████████████████████████████████████████████████████████████████▋                             | 619/872 [01:31<00:37,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|███████████████████████████████████████████████████████████████████████▊                             | 620/872 [01:31<00:37,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|███████████████████████████████████████████████████████████████████████▉                             | 621/872 [01:31<00:36,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|████████████████████████████████████████████████████████████████████████                             | 622/872 [01:31<00:37,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|████████████████████████████████████████████████████████████████████████▏                            | 623/872 [01:31<00:36,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|████████████████████████████████████████████████████████████████████████▎                            | 624/872 [01:31<00:37,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|████████████████████████████████████████████████████████████████████████▍                            | 625/872 [01:32<00:37,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|████████████████████████████████████████████████████████████████████████▌                            | 626/872 [01:32<00:37,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|████████████████████████████████████████████████████████████████████████▌                            | 627/872 [01:32<00:36,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|████████████████████████████████████████████████████████████████████████▋                            | 628/872 [01:32<00:36,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|████████████████████████████████████████████████████████████████████████▊                            | 629/872 [01:32<00:36,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|████████████████████████████████████████████████████████████████████████▉                            | 630/872 [01:32<00:36,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|█████████████████████████████████████████████████████████████████████████                            | 631/872 [01:33<00:36,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|█████████████████████████████████████████████████████████████████████████▏                           | 632/872 [01:33<00:36,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|█████████████████████████████████████████████████████████████████████████▎                           | 633/872 [01:33<00:36,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|█████████████████████████████████████████████████████████████████████████▍                           | 634/872 [01:33<00:35,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|█████████████████████████████████████████████████████████████████████████▌                           | 635/872 [01:33<00:35,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|█████████████████████████████████████████████████████████████████████████▋                           | 636/872 [01:33<00:35,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|█████████████████████████████████████████████████████████████████████████▊                           | 637/872 [01:33<00:35,  6.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|█████████████████████████████████████████████████████████████████████████▉                           | 638/872 [01:34<00:35,  6.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|██████████████████████████████████████████████████████████████████████████                           | 639/872 [01:34<00:35,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|██████████████████████████████████████████████████████████████████████████▏                          | 640/872 [01:34<00:35,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|██████████████████████████████████████████████████████████████████████████▏                          | 641/872 [01:34<00:34,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|██████████████████████████████████████████████████████████████████████████▎                          | 642/872 [01:34<00:34,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|██████████████████████████████████████████████████████████████████████████▍                          | 643/872 [01:34<00:34,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|██████████████████████████████████████████████████████████████████████████▌                          | 644/872 [01:34<00:34,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|██████████████████████████████████████████████████████████████████████████▋                          | 645/872 [01:35<00:33,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|██████████████████████████████████████████████████████████████████████████▊                          | 646/872 [01:35<00:33,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|██████████████████████████████████████████████████████████████████████████▉                          | 647/872 [01:35<00:33,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|███████████████████████████████████████████████████████████████████████████                          | 648/872 [01:35<00:36,  6.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|███████████████████████████████████████████████████████████████████████████▏                         | 649/872 [01:35<00:32,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|███████████████████████████████████████████████████████████████████████████▎                         | 650/872 [01:35<00:32,  6.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|███████████████████████████████████████████████████████████████████████████▍                         | 651/872 [01:36<00:33,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|███████████████████████████████████████████████████████████████████████████▌                         | 652/872 [01:36<00:33,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|███████████████████████████████████████████████████████████████████████████▋                         | 653/872 [01:36<00:31,  6.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|███████████████████████████████████████████████████████████████████████████▊                         | 654/872 [01:36<00:31,  6.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|███████████████████████████████████████████████████████████████████████████▊                         | 655/872 [01:36<00:32,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|███████████████████████████████████████████████████████████████████████████▉                         | 656/872 [01:36<00:32,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|████████████████████████████████████████████████████████████████████████████                         | 657/872 [01:36<00:32,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|████████████████████████████████████████████████████████████████████████████▏                        | 658/872 [01:37<00:32,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|████████████████████████████████████████████████████████████████████████████▎                        | 659/872 [01:37<00:32,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|████████████████████████████████████████████████████████████████████████████▍                        | 660/872 [01:37<00:31,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|████████████████████████████████████████████████████████████████████████████▌                        | 661/872 [01:37<00:31,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|████████████████████████████████████████████████████████████████████████████▋                        | 662/872 [01:37<00:31,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|████████████████████████████████████████████████████████████████████████████▊                        | 663/872 [01:37<00:31,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|████████████████████████████████████████████████████████████████████████████▉                        | 664/872 [01:37<00:30,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|█████████████████████████████████████████████████████████████████████████████                        | 665/872 [01:38<00:30,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|█████████████████████████████████████████████████████████████████████████████▏                       | 666/872 [01:38<00:28,  7.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|█████████████████████████████████████████████████████████████████████████████▎                       | 667/872 [01:38<00:29,  6.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|█████████████████████████████████████████████████████████████████████████████▎                       | 668/872 [01:38<00:29,  6.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|█████████████████████████████████████████████████████████████████████████████▍                       | 669/872 [01:38<00:29,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|█████████████████████████████████████████████████████████████████████████████▌                       | 670/872 [01:38<00:30,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|█████████████████████████████████████████████████████████████████████████████▋                       | 671/872 [01:38<00:29,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|█████████████████████████████████████████████████████████████████████████████▊                       | 672/872 [01:39<00:29,  6.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|█████████████████████████████████████████████████████████████████████████████▉                       | 673/872 [01:39<00:29,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|██████████████████████████████████████████████████████████████████████████████                       | 674/872 [01:39<00:27,  7.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|██████████████████████████████████████████████████████████████████████████████▏                      | 675/872 [01:39<00:27,  7.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|██████████████████████████████████████████████████████████████████████████████▎                      | 676/872 [01:39<00:28,  6.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|██████████████████████████████████████████████████████████████████████████████▍                      | 677/872 [01:39<00:28,  6.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|██████████████████████████████████████████████████████████████████████████████▌                      | 678/872 [01:39<00:28,  6.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|██████████████████████████████████████████████████████████████████████████████▋                      | 679/872 [01:40<00:28,  6.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|██████████████████████████████████████████████████████████████████████████████▊                      | 680/872 [01:40<00:28,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|██████████████████████████████████████████████████████████████████████████████▉                      | 681/872 [01:40<00:28,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|██████████████████████████████████████████████████████████████████████████████▉                      | 682/872 [01:40<00:28,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|███████████████████████████████████████████████████████████████████████████████                      | 683/872 [01:40<00:28,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|███████████████████████████████████████████████████████████████████████████████▏                     | 684/872 [01:40<00:28,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|███████████████████████████████████████████████████████████████████████████████▎                     | 685/872 [01:41<00:27,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|███████████████████████████████████████████████████████████████████████████████▍                     | 686/872 [01:41<00:27,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|███████████████████████████████████████████████████████████████████████████████▌                     | 687/872 [01:41<00:27,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|███████████████████████████████████████████████████████████████████████████████▋                     | 688/872 [01:41<00:27,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|███████████████████████████████████████████████████████████████████████████████▊                     | 689/872 [01:41<00:27,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|███████████████████████████████████████████████████████████████████████████████▉                     | 690/872 [01:41<00:27,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|████████████████████████████████████████████████████████████████████████████████                     | 691/872 [01:41<00:26,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|████████████████████████████████████████████████████████████████████████████████▏                    | 692/872 [01:42<00:26,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|████████████████████████████████████████████████████████████████████████████████▎                    | 693/872 [01:42<00:24,  7.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|████████████████████████████████████████████████████████████████████████████████▍                    | 694/872 [01:42<00:25,  6.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|████████████████████████████████████████████████████████████████████████████████▍                    | 695/872 [01:42<00:25,  6.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|████████████████████████████████████████████████████████████████████████████████▌                    | 696/872 [01:42<00:25,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|████████████████████████████████████████████████████████████████████████████████▋                    | 697/872 [01:42<00:25,  6.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|████████████████████████████████████████████████████████████████████████████████▊                    | 698/872 [01:42<00:25,  6.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|████████████████████████████████████████████████████████████████████████████████▉                    | 699/872 [01:43<00:25,  6.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|█████████████████████████████████████████████████████████████████████████████████                    | 700/872 [01:43<00:25,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|█████████████████████████████████████████████████████████████████████████████████▏                   | 701/872 [01:43<00:25,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|█████████████████████████████████████████████████████████████████████████████████▎                   | 702/872 [01:43<00:25,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|█████████████████████████████████████████████████████████████████████████████████▍                   | 703/872 [01:43<00:25,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|█████████████████████████████████████████████████████████████████████████████████▌                   | 704/872 [01:43<00:25,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|█████████████████████████████████████████████████████████████████████████████████▋                   | 705/872 [01:44<00:25,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|█████████████████████████████████████████████████████████████████████████████████▊                   | 706/872 [01:44<00:25,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|█████████████████████████████████████████████████████████████████████████████████▉                   | 707/872 [01:44<00:28,  5.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|██████████████████████████████████████████████████████████████████████████████████                   | 708/872 [01:44<00:27,  5.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|██████████████████████████████████████████████████████████████████████████████████                   | 709/872 [01:44<00:26,  6.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|██████████████████████████████████████████████████████████████████████████████████▏                  | 710/872 [01:44<00:25,  6.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|██████████████████████████████████████████████████████████████████████████████████▎                  | 711/872 [01:44<00:25,  6.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|██████████████████████████████████████████████████████████████████████████████████▍                  | 712/872 [01:45<00:24,  6.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|██████████████████████████████████████████████████████████████████████████████████▌                  | 713/872 [01:45<00:24,  6.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|██████████████████████████████████████████████████████████████████████████████████▋                  | 714/872 [01:45<00:23,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|██████████████████████████████████████████████████████████████████████████████████▊                  | 715/872 [01:45<00:23,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|██████████████████████████████████████████████████████████████████████████████████▉                  | 716/872 [01:45<00:23,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|███████████████████████████████████████████████████████████████████████████████████                  | 717/872 [01:45<00:23,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|███████████████████████████████████████████████████████████████████████████████████▏                 | 718/872 [01:46<00:23,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|███████████████████████████████████████████████████████████████████████████████████▎                 | 719/872 [01:46<00:23,  6.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|███████████████████████████████████████████████████████████████████████████████████▍                 | 720/872 [01:46<00:23,  6.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|███████████████████████████████████████████████████████████████████████████████████▌                 | 721/872 [01:46<00:23,  6.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|███████████████████████████████████████████████████████████████████████████████████▋                 | 722/872 [01:46<00:22,  6.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|███████████████████████████████████████████████████████████████████████████████████▋                 | 723/872 [01:46<00:22,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|███████████████████████████████████████████████████████████████████████████████████▊                 | 724/872 [01:46<00:22,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|███████████████████████████████████████████████████████████████████████████████████▉                 | 725/872 [01:47<00:22,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|████████████████████████████████████████████████████████████████████████████████████                 | 726/872 [01:47<00:22,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|████████████████████████████████████████████████████████████████████████████████████▏                | 727/872 [01:47<00:21,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|████████████████████████████████████████████████████████████████████████████████████▎                | 728/872 [01:47<00:21,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|████████████████████████████████████████████████████████████████████████████████████▍                | 729/872 [01:47<00:21,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|████████████████████████████████████████████████████████████████████████████████████▌                | 730/872 [01:47<00:21,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|████████████████████████████████████████████████████████████████████████████████████▋                | 731/872 [01:47<00:21,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|████████████████████████████████████████████████████████████████████████████████████▊                | 732/872 [01:48<00:21,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|████████████████████████████████████████████████████████████████████████████████████▉                | 733/872 [01:48<00:21,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|█████████████████████████████████████████████████████████████████████████████████████                | 734/872 [01:48<00:20,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|█████████████████████████████████████████████████████████████████████████████████████▏               | 735/872 [01:48<00:20,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|█████████████████████████████████████████████████████████████████████████████████████▏               | 736/872 [01:48<00:20,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|█████████████████████████████████████████████████████████████████████████████████████▎               | 737/872 [01:48<00:20,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|█████████████████████████████████████████████████████████████████████████████████████▍               | 738/872 [01:49<00:20,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|█████████████████████████████████████████████████████████████████████████████████████▌               | 739/872 [01:49<00:20,  6.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|█████████████████████████████████████████████████████████████████████████████████████▋               | 740/872 [01:49<00:20,  6.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|█████████████████████████████████████████████████████████████████████████████████████▊               | 741/872 [01:49<00:19,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|█████████████████████████████████████████████████████████████████████████████████████▉               | 742/872 [01:49<00:19,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|██████████████████████████████████████████████████████████████████████████████████████               | 743/872 [01:49<00:19,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|██████████████████████████████████████████████████████████████████████████████████████▏              | 744/872 [01:49<00:19,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|██████████████████████████████████████████████████████████████████████████████████████▎              | 745/872 [01:50<00:18,  6.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|██████████████████████████████████████████████████████████████████████████████████████▍              | 746/872 [01:50<00:18,  6.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|██████████████████████████████████████████████████████████████████████████████████████▌              | 747/872 [01:50<00:18,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|██████████████████████████████████████████████████████████████████████████████████████▋              | 748/872 [01:50<00:18,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|██████████████████████████████████████████████████████████████████████████████████████▊              | 749/872 [01:50<00:18,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|██████████████████████████████████████████████████████████████████████████████████████▊              | 750/872 [01:50<00:17,  7.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|██████████████████████████████████████████████████████████████████████████████████████▉              | 751/872 [01:50<00:17,  7.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|███████████████████████████████████████████████████████████████████████████████████████              | 752/872 [01:51<00:17,  6.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|███████████████████████████████████████████████████████████████████████████████████████▏             | 753/872 [01:51<00:17,  6.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|███████████████████████████████████████████████████████████████████████████████████████▎             | 754/872 [01:51<00:17,  6.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|███████████████████████████████████████████████████████████████████████████████████████▍             | 755/872 [01:51<00:17,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|███████████████████████████████████████████████████████████████████████████████████████▌             | 756/872 [01:51<00:17,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|███████████████████████████████████████████████████████████████████████████████████████▋             | 757/872 [01:51<00:17,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|███████████████████████████████████████████████████████████████████████████████████████▊             | 758/872 [01:52<00:17,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|███████████████████████████████████████████████████████████████████████████████████████▉             | 759/872 [01:52<00:16,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|████████████████████████████████████████████████████████████████████████████████████████             | 760/872 [01:52<00:16,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|████████████████████████████████████████████████████████████████████████████████████████▏            | 761/872 [01:52<00:16,  6.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|████████████████████████████████████████████████████████████████████████████████████████▎            | 762/872 [01:52<00:16,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|████████████████████████████████████████████████████████████████████████████████████████▍            | 763/872 [01:52<00:16,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|████████████████████████████████████████████████████████████████████████████████████████▍            | 764/872 [01:52<00:16,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|████████████████████████████████████████████████████████████████████████████████████████▌            | 765/872 [01:53<00:16,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|████████████████████████████████████████████████████████████████████████████████████████▋            | 766/872 [01:53<00:15,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|████████████████████████████████████████████████████████████████████████████████████████▊            | 767/872 [01:53<00:15,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|████████████████████████████████████████████████████████████████████████████████████████▉            | 768/872 [01:53<00:15,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|█████████████████████████████████████████████████████████████████████████████████████████            | 769/872 [01:53<00:15,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|█████████████████████████████████████████████████████████████████████████████████████████▏           | 770/872 [01:53<00:15,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|█████████████████████████████████████████████████████████████████████████████████████████▎           | 771/872 [01:53<00:15,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|█████████████████████████████████████████████████████████████████████████████████████████▍           | 772/872 [01:54<00:14,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|█████████████████████████████████████████████████████████████████████████████████████████▌           | 773/872 [01:54<00:14,  6.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|█████████████████████████████████████████████████████████████████████████████████████████▋           | 774/872 [01:54<00:14,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|█████████████████████████████████████████████████████████████████████████████████████████▊           | 775/872 [01:54<00:14,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|█████████████████████████████████████████████████████████████████████████████████████████▉           | 776/872 [01:54<00:14,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|█████████████████████████████████████████████████████████████████████████████████████████▉           | 777/872 [01:54<00:14,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|██████████████████████████████████████████████████████████████████████████████████████████           | 778/872 [01:55<00:14,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|██████████████████████████████████████████████████████████████████████████████████████████▏          | 779/872 [01:55<00:14,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|██████████████████████████████████████████████████████████████████████████████████████████▎          | 780/872 [01:55<00:13,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|██████████████████████████████████████████████████████████████████████████████████████████▍          | 781/872 [01:55<00:13,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|██████████████████████████████████████████████████████████████████████████████████████████▌          | 782/872 [01:55<00:13,  6.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|██████████████████████████████████████████████████████████████████████████████████████████▋          | 783/872 [01:55<00:13,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|██████████████████████████████████████████████████████████████████████████████████████████▊          | 784/872 [01:55<00:13,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|██████████████████████████████████████████████████████████████████████████████████████████▉          | 785/872 [01:56<00:13,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|███████████████████████████████████████████████████████████████████████████████████████████          | 786/872 [01:56<00:13,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|███████████████████████████████████████████████████████████████████████████████████████████▏         | 787/872 [01:56<00:12,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|███████████████████████████████████████████████████████████████████████████████████████████▎         | 788/872 [01:56<00:12,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|███████████████████████████████████████████████████████████████████████████████████████████▍         | 789/872 [01:56<00:12,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|███████████████████████████████████████████████████████████████████████████████████████████▌         | 790/872 [01:56<00:12,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|███████████████████████████████████████████████████████████████████████████████████████████▌         | 791/872 [01:57<00:13,  6.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|███████████████████████████████████████████████████████████████████████████████████████████▋         | 792/872 [01:57<00:12,  6.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|███████████████████████████████████████████████████████████████████████████████████████████▊         | 793/872 [01:57<00:12,  6.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|███████████████████████████████████████████████████████████████████████████████████████████▉         | 794/872 [01:57<00:12,  6.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|████████████████████████████████████████████████████████████████████████████████████████████         | 795/872 [01:57<00:11,  6.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|████████████████████████████████████████████████████████████████████████████████████████████▏        | 796/872 [01:57<00:11,  6.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|████████████████████████████████████████████████████████████████████████████████████████████▎        | 797/872 [01:57<00:11,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|████████████████████████████████████████████████████████████████████████████████████████████▍        | 798/872 [01:58<00:11,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|████████████████████████████████████████████████████████████████████████████████████████████▌        | 799/872 [01:58<00:10,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|████████████████████████████████████████████████████████████████████████████████████████████▋        | 800/872 [01:58<00:10,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|████████████████████████████████████████████████████████████████████████████████████████████▊        | 801/872 [01:58<00:10,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|████████████████████████████████████████████████████████████████████████████████████████████▉        | 802/872 [01:58<00:10,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|█████████████████████████████████████████████████████████████████████████████████████████████        | 803/872 [01:58<00:10,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|█████████████████████████████████████████████████████████████████████████████████████████████        | 804/872 [01:58<00:10,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|█████████████████████████████████████████████████████████████████████████████████████████████▏       | 805/872 [01:59<00:10,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|█████████████████████████████████████████████████████████████████████████████████████████████▎       | 806/872 [01:59<00:09,  6.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|█████████████████████████████████████████████████████████████████████████████████████████████▍       | 807/872 [01:59<00:09,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|█████████████████████████████████████████████████████████████████████████████████████████████▌       | 808/872 [01:59<00:09,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|█████████████████████████████████████████████████████████████████████████████████████████████▋       | 809/872 [01:59<00:09,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|█████████████████████████████████████████████████████████████████████████████████████████████▊       | 810/872 [01:59<00:09,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|█████████████████████████████████████████████████████████████████████████████████████████████▉       | 811/872 [02:00<00:09,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|██████████████████████████████████████████████████████████████████████████████████████████████       | 812/872 [02:00<00:08,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|██████████████████████████████████████████████████████████████████████████████████████████████▏      | 813/872 [02:00<00:08,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|██████████████████████████████████████████████████████████████████████████████████████████████▎      | 814/872 [02:00<00:08,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|██████████████████████████████████████████████████████████████████████████████████████████████▍      | 815/872 [02:00<00:08,  6.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|██████████████████████████████████████████████████████████████████████████████████████████████▌      | 816/872 [02:00<00:08,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|██████████████████████████████████████████████████████████████████████████████████████████████▋      | 817/872 [02:00<00:08,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|██████████████████████████████████████████████████████████████████████████████████████████████▋      | 818/872 [02:01<00:08,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|██████████████████████████████████████████████████████████████████████████████████████████████▊      | 819/872 [02:01<00:08,  6.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|██████████████████████████████████████████████████████████████████████████████████████████████▉      | 820/872 [02:01<00:08,  6.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|███████████████████████████████████████████████████████████████████████████████████████████████      | 821/872 [02:01<00:07,  6.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|███████████████████████████████████████████████████████████████████████████████████████████████▏     | 822/872 [02:01<00:07,  6.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|███████████████████████████████████████████████████████████████████████████████████████████████▎     | 823/872 [02:01<00:07,  6.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|███████████████████████████████████████████████████████████████████████████████████████████████▍     | 824/872 [02:02<00:07,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|███████████████████████████████████████████████████████████████████████████████████████████████▌     | 825/872 [02:02<00:07,  6.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|███████████████████████████████████████████████████████████████████████████████████████████████▋     | 826/872 [02:02<00:06,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|███████████████████████████████████████████████████████████████████████████████████████████████▊     | 827/872 [02:02<00:06,  6.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|███████████████████████████████████████████████████████████████████████████████████████████████▉     | 828/872 [02:02<00:06,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|████████████████████████████████████████████████████████████████████████████████████████████████     | 829/872 [02:02<00:06,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|████████████████████████████████████████████████████████████████████████████████████████████████▏    | 830/872 [02:02<00:06,  6.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|████████████████████████████████████████████████████████████████████████████████████████████████▎    | 831/872 [02:03<00:06,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|████████████████████████████████████████████████████████████████████████████████████████████████▎    | 832/872 [02:03<00:06,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|████████████████████████████████████████████████████████████████████████████████████████████████▍    | 833/872 [02:03<00:05,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|████████████████████████████████████████████████████████████████████████████████████████████████▌    | 834/872 [02:03<00:05,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|████████████████████████████████████████████████████████████████████████████████████████████████▋    | 835/872 [02:03<00:05,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|████████████████████████████████████████████████████████████████████████████████████████████████▊    | 836/872 [02:03<00:05,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|████████████████████████████████████████████████████████████████████████████████████████████████▉    | 837/872 [02:03<00:05,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████    | 838/872 [02:04<00:05,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████▏   | 839/872 [02:04<00:05,  6.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████▎   | 840/872 [02:04<00:04,  6.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████▍   | 841/872 [02:04<00:04,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████▌   | 842/872 [02:04<00:04,  6.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████▋   | 843/872 [02:04<00:04,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████▊   | 844/872 [02:05<00:04,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████▊   | 845/872 [02:05<00:04,  6.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████▉   | 846/872 [02:05<00:03,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|██████████████████████████████████████████████████████████████████████████████████████████████████   | 847/872 [02:05<00:03,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|██████████████████████████████████████████████████████████████████████████████████████████████████▏  | 848/872 [02:05<00:03,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|██████████████████████████████████████████████████████████████████████████████████████████████████▎  | 849/872 [02:05<00:03,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|██████████████████████████████████████████████████████████████████████████████████████████████████▍  | 850/872 [02:05<00:03,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████▌  | 851/872 [02:06<00:03,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████▋  | 852/872 [02:06<00:03,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████▊  | 853/872 [02:06<00:02,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████▉  | 854/872 [02:06<00:02,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████  | 855/872 [02:06<00:02,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████▏ | 856/872 [02:06<00:02,  6.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████▎ | 857/872 [02:07<00:02,  6.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████▍ | 858/872 [02:07<00:02,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████▍ | 859/872 [02:07<00:01,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████▌ | 860/872 [02:07<00:01,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████▋ | 861/872 [02:07<00:01,  6.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████▊ | 862/872 [02:07<00:01,  6.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████▉ | 863/872 [02:07<00:01,  6.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████ | 864/872 [02:08<00:01,  6.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████▏| 865/872 [02:08<00:01,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████▎| 866/872 [02:08<00:00,  6.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████▍| 867/872 [02:08<00:00,  6.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████▌| 868/872 [02:08<00:00,  6.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████▋| 869/872 [02:08<00:00,  6.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████▊| 870/872 [02:08<00:00,  6.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████▉| 871/872 [02:09<00:00,  6.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [02:09<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9599 (837/872)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "dev_df = pd.read_csv('./data/SST-2/dev.tsv', sep='\\t')\n",
    "sentences   = dev_df['sentence'].tolist()\n",
    "true_labels = dev_df['label'].tolist()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model     = AutoModelForCausalLM.from_pretrained(output_dir).to(device)\n",
    "model.eval()\n",
    "\n",
    "pred_labels = []\n",
    "for sent in tqdm(sentences, desc='Eval gen'):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Determine if the sentiment of this sentence is positive or negative. Answer with only 'positive' or 'negative'.\"},\n",
    "        {\"role\": \"user\",   \"content\": sent}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    if 'token_type_ids' in inputs: inputs.pop('token_type_ids')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=5,\n",
    "            temperature=0.1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    resp = tokenizer.decode(out[0][ inputs['input_ids'].shape[1]: ], skip_special_tokens=True).lower()\n",
    "\n",
    "    if 'positive' in resp:\n",
    "        pred_labels.append(1)\n",
    "    elif 'negative' in resp:\n",
    "        pred_labels.append(0)\n",
    "    else:\n",
    "        pred_labels.append(-1)  # 判定できず\n",
    "\n",
    "# 3) Accuracy計算\n",
    "correct = sum(1 for t, p in zip(true_labels, pred_labels) if t == p)\n",
    "total   = len(true_labels)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy:.4f} ({correct}/{total})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### llm-jp-3-150m-instruct3をフルファインチューニングした場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer,\n",
    "    Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'llm-jp/llm-jp-3-150m-instruct3'\n",
    "output_dir = 'output/llm-jp150m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map='auto',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_prompt(sentence, label, tokenizer):\n",
    "    instruction = '以下の文がポジティブかネガティブのどちらなのか判定してください．\"ポジティブ\"か\"ネガティブ\"で回答してください．'\n",
    "    content = f'''{instruction}\n",
    "\n",
    "{sentence}\n",
    "    '''\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": content}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    response = \"ポジティブ\" if label == 1 else \"ネガティブ\"\n",
    "    full_text = prompt + response + tokenizer.eos_token\n",
    "\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "\n",
      "### 指示:\n",
      "以下の文がポジティブかネガティブのどちらなのか判定してください．\"ポジティブ\"か\"ネガティブ\"で回答してください．\n",
      "\n",
      "あいうえお\n",
      "    \n",
      "\n",
      "### 応答:\n",
      "ポジティブ</s>\n"
     ]
    }
   ],
   "source": [
    "print(create_training_prompt(\"あいうえお\", 1, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer, max_length=512):\n",
    "    texts = []\n",
    "    for sentence, label in zip(examples['sentence'], examples['label']):\n",
    "        full_text = create_training_prompt(sentence, label, tokenizer)\n",
    "        texts.append(full_text)\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].clone()\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 67349\n",
      "Development samples: 872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('./data/SST-2/train.tsv', sep='\\t')\n",
    "dev_df = pd.read_csv('./data/SST-2/dev.tsv', sep='\\t')\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Development samples: {len(dev_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created successfully!\n",
      "Train dataset: Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 67349\n",
      "})\n",
      "Dev dataset: Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 872\n",
      "})\n",
      "\n",
      "First training example:\n",
      "Sentence: hide new secretions from the parental units \n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)\n",
    "\n",
    "print(\"Dataset created successfully!\")\n",
    "print(f\"Train dataset: {train_dataset}\")\n",
    "print(f\"Dev dataset: {dev_dataset}\")\n",
    "\n",
    "# データセットの内容確認\n",
    "print(f\"\\nFirst training example:\")\n",
    "print(f\"Sentence: {train_dataset[0]['sentence']}\")\n",
    "print(f\"Label: {train_dataset[0]['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3f8343aebf4510b99bf55b6dfce4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9462f61cc44b34a806dba083241c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed!\n",
      "Tokenized train dataset: Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 67349\n",
      "})\n",
      "Tokenized dev dataset: Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 872\n",
      "})\n",
      "\n",
      "First tokenized example:\n",
      "Input IDs length: 512\n",
      "Decoded text: <s><s> \n",
      "\n",
      "### 指示:\n",
      "以下の文がポジティブかネガティブのどちらなのか判定してください．\"ポジティブ\"か\"ネガティブ\"で回答してください．\n",
      "\n",
      "hide new secretions from the parental units \n",
      "    \n",
      "\n",
      "### 応答:\n",
      "ネガティブ</s><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp><PAD|LLM-jp>...\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(\n",
    "    lambda x: preprocess_function(x, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "tokenized_dev = dev_dataset.map(\n",
    "    lambda x: preprocess_function(x, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=dev_dataset.column_names\n",
    ")\n",
    "\n",
    "print(\"Tokenization completed!\")\n",
    "print(f\"Tokenized train dataset: {tokenized_train}\")\n",
    "print(f\"Tokenized dev dataset: {tokenized_dev}\")\n",
    "\n",
    "# トークナイズされたデータの確認\n",
    "print(f\"\\nFirst tokenized example:\")\n",
    "example = tokenized_train[0]\n",
    "print(f\"Input IDs length: {len(example['input_ids'])}\")\n",
    "print(f\"Decoded text: {tokenizer.decode(example['input_ids'][:100])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collator created!\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # 因果言語モデルなのでFalse\n",
    "    pad_to_multiple_of=8,  # 効率化のため\n",
    ")\n",
    "\n",
    "print(\"Data collator created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arguments configured!\n",
      "Output directory: output/llm-jp150m\n",
      "Batch size: 16\n",
      "Learning rate: 0.0002\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=16,  # メモリ制約に応じて調整\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,  # メモリ節約\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None,  # wandbなどの使用を無効化\n",
    ")\n",
    "\n",
    "print(\"Training arguments configured!\")\n",
    "print(f\"Output directory: {training_args.output_dir}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer created successfully!\n",
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21050' max='21050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21050/21050 1:48:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.210900</td>\n",
       "      <td>2.057077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.085200</td>\n",
       "      <td>1.973935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.983900</td>\n",
       "      <td>1.995480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.906300</td>\n",
       "      <td>1.999902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>2.009927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.753100</td>\n",
       "      <td>2.020245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.731500</td>\n",
       "      <td>2.082959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>2.097728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.542300</td>\n",
       "      <td>2.251677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.531900</td>\n",
       "      <td>2.294180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.504400</td>\n",
       "      <td>2.357603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>2.346084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>2.418404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>2.417850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.438500</td>\n",
       "      <td>2.435267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>2.495339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.361300</td>\n",
       "      <td>2.687800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>2.679011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.347300</td>\n",
       "      <td>2.721622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>2.706643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>2.714417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.343300</td>\n",
       "      <td>2.734882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>2.750339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>2.750545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>2.795432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.282300</td>\n",
       "      <td>3.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>2.951562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>2.978519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>3.039967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>2.997046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.284500</td>\n",
       "      <td>3.009785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>3.048230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.280100</td>\n",
       "      <td>3.073042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>3.210881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>3.227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>3.226163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.249800</td>\n",
       "      <td>3.220452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>3.202241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.248800</td>\n",
       "      <td>3.241208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>3.229621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.249100</td>\n",
       "      <td>3.245098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>3.258632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning completed!\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Trainer created successfully!\")\n",
    "print(\"Starting fine-tuning...\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"Fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to output/llm-jp150m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 3.2585337162017822, 'eval_runtime': 6.1477, 'eval_samples_per_second': 141.842, 'eval_steps_per_second': 8.946, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval gen:   0%|                                                                                                                                                                                                              | 0/872 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   0%|▋                                                                                                                                                                                                     | 3/872 [00:00<00:33, 25.76it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|█▌                                                                                                                                                                                                    | 7/872 [00:00<00:28, 30.81it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   1%|██▍                                                                                                                                                                                                  | 11/872 [00:00<00:26, 32.20it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|███▌                                                                                                                                                                                                 | 16/872 [00:00<00:23, 36.88it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   2%|████▋                                                                                                                                                                                                | 21/872 [00:00<00:21, 39.76it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|█████▋                                                                                                                                                                                               | 25/872 [00:00<00:22, 37.64it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   3%|██████▌                                                                                                                                                                                              | 29/872 [00:00<00:25, 33.57it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|███████▋                                                                                                                                                                                             | 34/872 [00:00<00:22, 36.93it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   4%|████████▊                                                                                                                                                                                            | 39/872 [00:01<00:21, 39.42it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   5%|█████████▉                                                                                                                                                                                           | 44/872 [00:01<00:22, 36.29it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|███████████                                                                                                                                                                                          | 49/872 [00:01<00:22, 36.11it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   6%|███████████▉                                                                                                                                                                                         | 53/872 [00:01<00:23, 35.32it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|█████████████                                                                                                                                                                                        | 58/872 [00:01<00:21, 37.89it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   7%|██████████████▏                                                                                                                                                                                      | 63/872 [00:01<00:20, 39.95it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|███████████████▎                                                                                                                                                                                     | 68/872 [00:01<00:20, 38.77it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   8%|████████████████▍                                                                                                                                                                                    | 73/872 [00:01<00:19, 40.31it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:   9%|█████████████████▌                                                                                                                                                                                   | 78/872 [00:02<00:19, 41.64it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|██████████████████▊                                                                                                                                                                                  | 83/872 [00:02<00:21, 37.31it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  10%|███████████████████▉                                                                                                                                                                                 | 88/872 [00:02<00:21, 36.85it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|████████████████████▊                                                                                                                                                                                | 92/872 [00:02<00:22, 35.22it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|█████████████████████▋                                                                                                                                                                               | 96/872 [00:02<00:23, 32.70it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  11%|██████████████████████▍                                                                                                                                                                             | 100/872 [00:02<00:23, 33.05it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|███████████████████████▍                                                                                                                                                                            | 104/872 [00:02<00:23, 33.31it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  12%|████████████████████████▎                                                                                                                                                                           | 108/872 [00:02<00:22, 33.59it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|█████████████████████████▏                                                                                                                                                                          | 112/872 [00:03<00:23, 31.88it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  13%|██████████████████████████                                                                                                                                                                          | 116/872 [00:03<00:25, 29.34it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|██████████████████████████▉                                                                                                                                                                         | 120/872 [00:03<00:24, 30.51it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  14%|████████████████████████████                                                                                                                                                                        | 125/872 [00:03<00:21, 34.33it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|████████████████████████████▉                                                                                                                                                                       | 129/872 [00:03<00:21, 34.47it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  15%|█████████████████████████████▉                                                                                                                                                                      | 133/872 [00:03<00:21, 34.73it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|██████████████████████████████▊                                                                                                                                                                     | 137/872 [00:03<00:21, 34.77it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  16%|███████████████████████████████▉                                                                                                                                                                    | 142/872 [00:03<00:19, 37.69it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|████████████████████████████████▊                                                                                                                                                                   | 146/872 [00:04<00:19, 36.77it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  17%|█████████████████████████████████▉                                                                                                                                                                  | 151/872 [00:04<00:19, 36.85it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|██████████████████████████████████▊                                                                                                                                                                 | 155/872 [00:04<00:21, 34.00it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  18%|███████████████████████████████████▋                                                                                                                                                                | 159/872 [00:04<00:20, 34.00it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|████████████████████████████████████▋                                                                                                                                                               | 163/872 [00:04<00:20, 34.24it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  19%|█████████████████████████████████████▌                                                                                                                                                              | 167/872 [00:04<00:20, 34.49it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|██████████████████████████████████████▍                                                                                                                                                             | 171/872 [00:04<00:20, 34.47it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  20%|███████████████████████████████████████▌                                                                                                                                                            | 176/872 [00:04<00:19, 35.07it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|████████████████████████████████████████▍                                                                                                                                                           | 180/872 [00:05<00:21, 32.85it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  21%|█████████████████████████████████████████▎                                                                                                                                                          | 184/872 [00:05<00:20, 33.48it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|██████████████████████████████████████████▍                                                                                                                                                         | 189/872 [00:05<00:18, 36.36it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  22%|███████████████████████████████████████████▍                                                                                                                                                        | 193/872 [00:05<00:18, 35.84it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|████████████████████████████████████████████▎                                                                                                                                                       | 197/872 [00:05<00:20, 33.19it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  23%|█████████████████████████████████████████████▏                                                                                                                                                      | 201/872 [00:05<00:19, 33.72it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|██████████████████████████████████████████████                                                                                                                                                      | 205/872 [00:05<00:22, 30.02it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|██████████████████████████████████████████████▉                                                                                                                                                     | 209/872 [00:06<00:21, 30.95it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  24%|███████████████████████████████████████████████▉                                                                                                                                                    | 213/872 [00:06<00:21, 31.36it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|████████████████████████████████████████████████▊                                                                                                                                                   | 217/872 [00:06<00:21, 30.03it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  25%|█████████████████████████████████████████████████▋                                                                                                                                                  | 221/872 [00:06<00:23, 27.71it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|██████████████████████████████████████████████████▌                                                                                                                                                 | 225/872 [00:06<00:21, 29.48it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  26%|███████████████████████████████████████████████████▋                                                                                                                                                | 230/872 [00:06<00:19, 33.77it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|████████████████████████████████████████████████████▊                                                                                                                                               | 235/872 [00:06<00:17, 36.92it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  27%|█████████████████████████████████████████████████████▋                                                                                                                                              | 239/872 [00:06<00:18, 33.67it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|██████████████████████████████████████████████████████▌                                                                                                                                             | 243/872 [00:07<00:18, 33.74it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  28%|███████████████████████████████████████████████████████▋                                                                                                                                            | 248/872 [00:07<00:16, 36.97it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|████████████████████████████████████████████████████████▋                                                                                                                                           | 252/872 [00:07<00:17, 36.41it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  29%|█████████████████████████████████████████████████████████▌                                                                                                                                          | 256/872 [00:07<00:17, 35.54it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|██████████████████████████████████████████████████████████▍                                                                                                                                         | 260/872 [00:07<00:18, 33.00it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  30%|███████████████████████████████████████████████████████████▎                                                                                                                                        | 264/872 [00:07<00:19, 31.41it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|████████████████████████████████████████████████████████████▏                                                                                                                                       | 268/872 [00:07<00:19, 30.39it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  31%|█████████████████████████████████████████████████████████████▎                                                                                                                                      | 273/872 [00:07<00:17, 34.42it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|██████████████████████████████████████████████████████████████▎                                                                                                                                     | 277/872 [00:08<00:17, 34.45it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  32%|███████████████████████████████████████████████████████████████▍                                                                                                                                    | 282/872 [00:08<00:15, 37.29it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|████████████████████████████████████████████████████████████████▎                                                                                                                                   | 286/872 [00:08<00:15, 36.63it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  33%|█████████████████████████████████████████████████████████████████▏                                                                                                                                  | 290/872 [00:08<00:16, 36.13it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████████████████████████████████████                                                                                                                                  | 294/872 [00:08<00:17, 33.42it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  34%|██████████████████████████████████████████████████████████████████▉                                                                                                                                 | 298/872 [00:08<00:17, 33.71it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|███████████████████████████████████████████████████████████████████▉                                                                                                                                | 302/872 [00:08<00:16, 34.09it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  35%|████████████████████████████████████████████████████████████████████▊                                                                                                                               | 306/872 [00:08<00:16, 34.30it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|█████████████████████████████████████████████████████████████████████▋                                                                                                                              | 310/872 [00:08<00:16, 34.19it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  36%|██████████████████████████████████████████████████████████████████████▌                                                                                                                             | 314/872 [00:09<00:16, 34.28it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|███████████████████████████████████████████████████████████████████████▋                                                                                                                            | 319/872 [00:09<00:14, 37.50it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  37%|████████████████████████████████████████████████████████████████████████▌                                                                                                                           | 323/872 [00:09<00:14, 36.75it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 328/872 [00:09<00:13, 39.08it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  38%|██████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 333/872 [00:09<00:13, 40.83it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|███████████████████████████████████████████████████████████████████████████▉                                                                                                                        | 338/872 [00:09<00:13, 39.22it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  39%|████████████████████████████████████████████████████████████████████████████▊                                                                                                                       | 342/872 [00:09<00:14, 35.60it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|█████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 346/872 [00:09<00:15, 33.28it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  40%|██████████████████████████████████████████████████████████████████████████████▉                                                                                                                     | 351/872 [00:10<00:14, 36.43it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|████████████████████████████████████████████████████████████████████████████████                                                                                                                    | 356/872 [00:10<00:13, 38.87it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  41%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 361/872 [00:10<00:13, 38.09it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 365/872 [00:10<00:13, 37.13it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  42%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 369/872 [00:10<00:13, 36.35it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|███████████████████████████████████████████████████████████████████████████████████▊                                                                                                                | 373/872 [00:10<00:13, 35.79it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  43%|████████████████████████████████████████████████████████████████████████████████████▋                                                                                                               | 377/872 [00:10<00:14, 33.13it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 382/872 [00:10<00:14, 33.89it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  44%|██████████████████████████████████████████████████████████████████████████████████████▊                                                                                                             | 386/872 [00:11<00:14, 33.88it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|███████████████████████████████████████████████████████████████████████████████████████▋                                                                                                            | 390/872 [00:11<00:14, 34.05it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  45%|████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 394/872 [00:11<00:14, 32.14it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 398/872 [00:11<00:14, 32.84it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  46%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 403/872 [00:11<00:13, 35.76it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 407/872 [00:11<00:14, 31.20it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  47%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                       | 412/872 [00:11<00:13, 34.80it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 416/872 [00:11<00:13, 32.65it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  48%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                     | 420/872 [00:12<00:13, 33.20it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                    | 424/872 [00:12<00:13, 33.54it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  49%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 429/872 [00:12<00:12, 36.82it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 434/872 [00:12<00:11, 39.30it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  50%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                 | 439/872 [00:12<00:10, 41.09it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 444/872 [00:12<00:10, 39.45it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  51%|████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 449/872 [00:12<00:10, 40.97it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  52%|██████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                              | 454/872 [00:12<00:09, 42.23it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                            | 459/872 [00:13<00:10, 39.99it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  53%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 464/872 [00:13<00:09, 41.55it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 469/872 [00:13<00:10, 39.78it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                         | 474/872 [00:13<00:10, 38.83it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 479/872 [00:13<00:10, 37.88it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 483/872 [00:13<00:10, 36.76it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 488/872 [00:13<00:10, 36.69it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                     | 493/872 [00:13<00:09, 39.11it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                    | 497/872 [00:14<00:09, 38.60it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 502/872 [00:14<00:09, 40.55it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  58%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 507/872 [00:14<00:08, 41.77it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                 | 512/872 [00:14<00:08, 42.82it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 517/872 [00:14<00:09, 38.17it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 521/872 [00:14<00:09, 37.24it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                             | 526/872 [00:14<00:08, 39.35it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                            | 531/872 [00:14<00:08, 40.97it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 536/872 [00:15<00:08, 39.25it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                          | 540/872 [00:15<00:08, 37.96it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 544/872 [00:15<00:08, 37.05it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  63%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 549/872 [00:15<00:08, 39.47it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                       | 554/872 [00:15<00:07, 41.38it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                      | 559/872 [00:15<00:07, 42.60it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 564/872 [00:15<00:08, 35.27it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 568/872 [00:15<00:08, 35.14it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                   | 573/872 [00:15<00:07, 37.96it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                  | 577/872 [00:16<00:07, 37.03it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 582/872 [00:16<00:07, 39.58it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 587/872 [00:16<00:06, 41.17it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 592/872 [00:16<00:07, 39.52it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 597/872 [00:16<00:06, 41.15it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 602/872 [00:16<00:06, 42.53it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                           | 607/872 [00:16<00:06, 43.35it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                          | 612/872 [00:16<00:05, 44.01it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 617/872 [00:17<00:06, 38.45it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 622/872 [00:17<00:06, 40.32it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 627/872 [00:17<00:06, 39.01it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                      | 631/872 [00:17<00:06, 35.54it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 635/872 [00:17<00:06, 35.33it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 639/872 [00:17<00:06, 34.99it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 643/872 [00:17<00:07, 32.44it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 648/872 [00:17<00:06, 35.91it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 652/872 [00:18<00:06, 35.91it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 657/872 [00:18<00:05, 38.23it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 661/872 [00:18<00:05, 36.77it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 666/872 [00:18<00:05, 38.92it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  77%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 671/872 [00:18<00:04, 40.81it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                            | 676/872 [00:18<00:05, 34.65it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 680/872 [00:18<00:05, 32.61it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 685/872 [00:18<00:05, 35.83it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 689/872 [00:19<00:05, 31.23it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 694/872 [00:19<00:05, 34.70it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 698/872 [00:19<00:05, 30.70it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 703/872 [00:19<00:04, 34.32it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                    | 708/872 [00:19<00:04, 37.16it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 713/872 [00:19<00:04, 39.25it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 718/872 [00:19<00:03, 40.59it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 723/872 [00:20<00:03, 39.19it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 728/872 [00:20<00:03, 36.03it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 733/872 [00:20<00:03, 38.46it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 737/872 [00:20<00:03, 37.21it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 741/872 [00:20<00:03, 35.73it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                            | 745/872 [00:20<00:04, 30.40it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 749/872 [00:20<00:03, 31.01it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 753/872 [00:20<00:03, 32.07it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 758/872 [00:21<00:03, 35.79it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                        | 762/872 [00:21<00:03, 35.29it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 767/872 [00:21<00:02, 38.37it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 772/872 [00:21<00:02, 40.69it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 777/872 [00:21<00:02, 42.23it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 782/872 [00:21<00:02, 40.45it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 787/872 [00:21<00:02, 39.40it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                  | 792/872 [00:21<00:01, 40.73it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 797/872 [00:21<00:01, 42.16it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 802/872 [00:22<00:01, 43.27it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 807/872 [00:22<00:01, 41.21it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 812/872 [00:22<00:01, 37.41it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 816/872 [00:22<00:01, 36.73it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 821/872 [00:22<00:01, 39.31it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 826/872 [00:22<00:01, 36.28it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 831/872 [00:22<00:01, 38.93it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 836/872 [00:23<00:01, 35.84it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 840/872 [00:23<00:00, 35.31it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 844/872 [00:23<00:00, 33.09it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 849/872 [00:23<00:00, 36.58it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 854/872 [00:23<00:00, 39.12it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 859/872 [00:23<00:00, 38.37it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 864/872 [00:23<00:00, 40.57it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 869/872 [00:23<00:00, 36.63it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Eval gen: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [00:24<00:00, 36.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6342 (553/872)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "dev_df = pd.read_csv('./data/SST-2/dev.tsv', sep='\\t')\n",
    "sentences   = dev_df['sentence'].tolist()\n",
    "true_labels = dev_df['label'].tolist()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model     = AutoModelForCausalLM.from_pretrained(output_dir).to(device)\n",
    "model.eval()\n",
    "\n",
    "pred_labels = []\n",
    "for sent in tqdm(sentences, desc='Eval gen'):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"以下の文がポジティブかネガティブのどちらなのか判定してください．\\\"ポジティブ\\\"か\\\"ネガティブ\\\"で回答してください．\"},\n",
    "        {\"role\": \"user\",   \"content\": sent}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    if 'token_type_ids' in inputs: inputs.pop('token_type_ids')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=5,\n",
    "            temperature=0.1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    resp = tokenizer.decode(out[0][ inputs['input_ids'].shape[1]: ], skip_special_tokens=True).lower()\n",
    "\n",
    "    if 'ポジティブ' in resp:\n",
    "        pred_labels.append(1)\n",
    "    elif 'ネガティブ' in resp:\n",
    "        pred_labels.append(0)\n",
    "    else:\n",
    "        pred_labels.append(-1)  # 判定できず\n",
    "\n",
    "# 3) Accuracy計算\n",
    "correct = sum(1 for t, p in zip(true_labels, pred_labels) if t == p)\n",
    "total   = len(true_labels)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy:.4f} ({correct}/{total})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "4f0St5Ce0l34",
    "tags": []
   },
   "source": [
    "## 99. 選好チューニング\n",
    "\n",
    "問題96のプロンプトに対して、正解の感情ラベルを含むテキストを望ましい応答、間違った感情ラベルを含むテキストを望ましくない応答として、事前学習済み言語モデルを選好チューニング (preference tuning) を実施せよ。選好チューニングのアルゴリズムとしては、近傍方策最適化 (PPO: Proximal Policy Optimization) や直接選好最適化 (DPO: Direct Preference Optimization) などが考えられる。\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a56790cc58c4155bb4fb62352fe6853": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c4e978f772946f293451de4484720ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da96a5f6901649958e682be81f939149",
      "placeholder": "​",
      "style": "IPY_MODEL_3f9c4fcaa07b42a0971b99205dd05458",
      "value": " 1/1 [00:00&lt;00:00, 25.67it/s]"
     }
    },
    "0f1172658036407993eb46da17554501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd75431e52b54d9bb2fd7c06737c28f5",
      "placeholder": "​",
      "style": "IPY_MODEL_12c4ec93b2fc4b239b775d5b947b253f",
      "value": " 67349/0 [00:00&lt;00:00, 674165.72 examples/s]"
     }
    },
    "12c4ec93b2fc4b239b775d5b947b253f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1411c82bf2f3475a826a145fb9f89626": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "145b34f60df1429e8685bcc9b2f05be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c8a470363f246d692c48ab4a502c4c7",
      "max": 872,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae5b03ae867f4ffba662a8888b319926",
      "value": 872
     }
    },
    "14c91ad60bc84fb0a9c6cc1eb9365425": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b91de93f8ec46c2ac153f40f50ae2e0",
      "placeholder": "​",
      "style": "IPY_MODEL_f4367d9584aa42e0b4249b33af0435d9",
      "value": "Generating train split: "
     }
    },
    "16763c09bfa34f03821316fe7c9902e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c57bd417124c4faa8652b13e826405db",
       "IPY_MODEL_3248b0100e614e2a89b0e2dc13be0ad5",
       "IPY_MODEL_936c040e05bc4b2aadd82245d0c2f3b3"
      ],
      "layout": "IPY_MODEL_a1aac38df0bd43bf9a48a55be029f499"
     }
    },
    "1860eb6e26ca45aeab8ab4ab41334a25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29245bfd86f0460ea2bfccaca75690a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e33f53fccce4875bbb245afe5b87cf3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5cbbe2769e024a92a5aa718d8f889d0f",
      "value": 1
     }
    },
    "2b91de93f8ec46c2ac153f40f50ae2e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3248b0100e614e2a89b0e2dc13be0ad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93d07d6d16da45b2a248ad37e51c3180",
      "max": 67349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a03ab49faf2a4027906a0e9f806bd2db",
      "value": 67349
     }
    },
    "3c41fe7af38f49f581ae359b5d970d23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f95aef5e2c74acd8ffbfad2543b2102",
      "placeholder": "​",
      "style": "IPY_MODEL_9a20391390dd4f96aaea37321b4dfb53",
      "value": " 872/0 [00:00&lt;00:00, 66375.69 examples/s]"
     }
    },
    "3f6a346c2abd42ea9fb5af9441376472": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97484a182f634ec8a711d516fdeb0c63",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7453ed4be064ab586858e8dec61ffae",
      "value": 1
     }
    },
    "3f95aef5e2c74acd8ffbfad2543b2102": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f9c4fcaa07b42a0971b99205dd05458": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b8bf221e7974b65b4dde96219ce0f47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bc6646a088f4bd7b58b33ae1bbab1ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d1eef416f5944c2911154fb770d869f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54587b2141984fd495bf55ea6df0d1a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d603aabb8b6443d2a66b94701858f523",
      "placeholder": "​",
      "style": "IPY_MODEL_1411c82bf2f3475a826a145fb9f89626",
      "value": "Generating dev split: "
     }
    },
    "5cbbe2769e024a92a5aa718d8f889d0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "64ebcabb9c26423f8cda28966d9bbedb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "678df530cc994774899eb213581f737b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c8a470363f246d692c48ab4a502c4c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75a29e01568b4272832f3e00dd92a707": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80837417e00b4fd3814524786898697c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81b067d9308141c786bc70f709681ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54587b2141984fd495bf55ea6df0d1a5",
       "IPY_MODEL_29245bfd86f0460ea2bfccaca75690a1",
       "IPY_MODEL_3c41fe7af38f49f581ae359b5d970d23"
      ],
      "layout": "IPY_MODEL_4bc6646a088f4bd7b58b33ae1bbab1ae"
     }
    },
    "8dec4107d6a44cdaae9020345e2c25a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e33f53fccce4875bbb245afe5b87cf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "936c040e05bc4b2aadd82245d0c2f3b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64ebcabb9c26423f8cda28966d9bbedb",
      "placeholder": "​",
      "style": "IPY_MODEL_678df530cc994774899eb213581f737b",
      "value": " 67349/67349 [00:03&lt;00:00, 20324.02 examples/s]"
     }
    },
    "93d07d6d16da45b2a248ad37e51c3180": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97484a182f634ec8a711d516fdeb0c63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "9a20391390dd4f96aaea37321b4dfb53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a03ab49faf2a4027906a0e9f806bd2db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1aac38df0bd43bf9a48a55be029f499": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3164d72e2d5431dbd7921b74290193a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3cd48beab0741b99a7885f89ebe1181": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8eb7b58bb3a4bfc9d4dad2bc0857dbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4da859c892b42cfa6c909e7dfe2df7d",
       "IPY_MODEL_df8979acad044b40bb55c3e00c418e05",
       "IPY_MODEL_0c4e978f772946f293451de4484720ed"
      ],
      "layout": "IPY_MODEL_b913e33aebe642cca6fa8a6ade682988"
     }
    },
    "ae5b03ae867f4ffba662a8888b319926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1763f6b7fc9430ab2f773279fdd954d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75a29e01568b4272832f3e00dd92a707",
      "placeholder": "​",
      "style": "IPY_MODEL_8dec4107d6a44cdaae9020345e2c25a4",
      "value": "Map: 100%"
     }
    },
    "b913e33aebe642cca6fa8a6ade682988": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd75431e52b54d9bb2fd7c06737c28f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0929c9ec77a48df8a7fd3e2f4539a51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c57bd417124c4faa8652b13e826405db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1860eb6e26ca45aeab8ab4ab41334a25",
      "placeholder": "​",
      "style": "IPY_MODEL_4b8bf221e7974b65b4dde96219ce0f47",
      "value": "Map: 100%"
     }
    },
    "d5e5c6c318cc41c4ac40647e6d5a5106": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14c91ad60bc84fb0a9c6cc1eb9365425",
       "IPY_MODEL_3f6a346c2abd42ea9fb5af9441376472",
       "IPY_MODEL_0f1172658036407993eb46da17554501"
      ],
      "layout": "IPY_MODEL_0a56790cc58c4155bb4fb62352fe6853"
     }
    },
    "d603aabb8b6443d2a66b94701858f523": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7453ed4be064ab586858e8dec61ffae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da96a5f6901649958e682be81f939149": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deee5780a392426096c2ff4f76aa1547": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df8979acad044b40bb55c3e00c418e05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec97a156272345ba8d456c5f090d9412",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_deee5780a392426096c2ff4f76aa1547",
      "value": 1
     }
    },
    "e92b3187acda44e9b30051a9e410f43f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b1763f6b7fc9430ab2f773279fdd954d",
       "IPY_MODEL_145b34f60df1429e8685bcc9b2f05be2",
       "IPY_MODEL_fc589f87f65d4a3196cdd790bbdf7fa0"
      ],
      "layout": "IPY_MODEL_c0929c9ec77a48df8a7fd3e2f4539a51"
     }
    },
    "ec97a156272345ba8d456c5f090d9412": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4367d9584aa42e0b4249b33af0435d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4da859c892b42cfa6c909e7dfe2df7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d1eef416f5944c2911154fb770d869f",
      "placeholder": "​",
      "style": "IPY_MODEL_a3164d72e2d5431dbd7921b74290193a",
      "value": "100%"
     }
    },
    "fc589f87f65d4a3196cdd790bbdf7fa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3cd48beab0741b99a7885f89ebe1181",
      "placeholder": "​",
      "style": "IPY_MODEL_80837417e00b4fd3814524786898697c",
      "value": " 872/872 [00:00&lt;00:00, 9939.81 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
