{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d2e8296-0efe-488a-9303-c53e0aac5573",
      "metadata": {
        "editable": true,
        "id": "5d2e8296-0efe-488a-9303-c53e0aac5573",
        "tags": []
      },
      "source": [
        "# 第1章: 準備運動"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b25a842d-828c-4fcd-b23e-62fcdbabc4dd",
      "metadata": {
        "editable": true,
        "id": "b25a842d-828c-4fcd-b23e-62fcdbabc4dd",
        "tags": []
      },
      "source": [
        "## 00. パタトクカシーー\n",
        "2つの文字列「パトカー」と「タクシー」の文字を先頭から交互に連結し、文字列「パタトクカシーー」を得よ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = 'パトカー'\n",
        "t = 'タクシー'\n",
        "\n",
        "print([a + b for a, b in zip(p, t)])\n",
        "res = ''.join([a + b for a, b in zip(p, t)])\n",
        "\n",
        "print (res)"
      ],
      "metadata": {
        "id": "4SXXvkhqajvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ee5d0b-664e-451b-8ca1-f93a41d8591f"
      },
      "id": "4SXXvkhqajvF",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['パタ', 'トク', 'カシ', 'ーー']\n",
            "パタトクカシーー\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "552596a9-f286-49b1-8443-ceb3454889e0",
      "metadata": {
        "editable": true,
        "id": "552596a9-f286-49b1-8443-ceb3454889e0",
        "tags": []
      },
      "source": [
        "## 01. タクシー\n",
        "文字列「パタトクカシーー」の2, 4, 6, 8文字目を取り出し、それらを連結した文字列を得よ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res[1::2])"
      ],
      "metadata": {
        "id": "qE42mxaa09uB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83c7e9a-9726-4b9f-effd-f20937ea1a05"
      },
      "id": "qE42mxaa09uB",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "タクシー\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = \"abcd\"\n",
        "b = a.split()\n",
        "print(b)\n",
        "\n",
        "c = list(a)\n",
        "print(c)"
      ],
      "metadata": {
        "id": "7_LZ9yppiKOU",
        "outputId": "dcf3bfe4-a526-462f-f23a-cabee2224ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7_LZ9yppiKOU",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcd']\n",
            "['a', 'b', 'c', 'd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c0a9a7c-4ade-4023-9f44-fc9cf394978b",
      "metadata": {
        "editable": true,
        "id": "1c0a9a7c-4ade-4023-9f44-fc9cf394978b",
        "tags": []
      },
      "source": [
        "## 02. 文字列の逆順\n",
        "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = 'stressed'\n",
        "print(s[::-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKGUN-_dYaPr",
        "outputId": "e84852a1-a992-4ea3-9de0-e76af1b4ce65"
      },
      "id": "MKGUN-_dYaPr",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s', 't', 'r', 'e', 's', 's', 'e', 'd']\n",
            "<list_reverseiterator object at 0x7ac1b6b657e0>\n",
            "desserts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4161bcb5-5baf-4172-b2a6-7c14f1907d54",
      "metadata": {
        "id": "4161bcb5-5baf-4172-b2a6-7c14f1907d54"
      },
      "source": [
        "## 03. 円周率\n",
        "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し、各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
        "sentence = sentence.replace(',', '')\n",
        "sentence = sentence.replace('.', '')\n",
        "\n",
        "print(sentence)\n",
        "\n",
        "words = sentence.split()\n",
        "\n",
        "word_length = [len(word) for word in words]\n",
        "\n",
        "print(word_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npTHvq2_iFLk",
        "outputId": "f9f0ed24-2f89-462a-fccb-7c5e49b16087"
      },
      "id": "npTHvq2_iFLk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now I need a drink alcoholic of course after the heavy lectures involving quantum mechanics\n",
            "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e56c958-d6fb-411c-9dc6-77992c515637",
      "metadata": {
        "id": "8e56c958-d6fb-411c-9dc6-77992c515637"
      },
      "source": [
        "## 04. 元素記号\n",
        "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し、1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字、それ以外の単語は先頭の2文字を取り出し、取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_list = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
        "sentence = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
        "sentence = sentence.replace(',', '')\n",
        "sentence = sentence.replace('.', '')\n",
        "\n",
        "words = sentence.split()\n",
        "word_dict = {}\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "    if i + 1 in index_list:\n",
        "        word_dict[word[:1]] = i + 1\n",
        "    else:\n",
        "        word_dict[word[:2]] = i + 1\n",
        "print(word_dict)"
      ],
      "metadata": {
        "id": "pYdP1-8l19j3",
        "outputId": "0cd87bb0-64ea-4f1f-c7ea-82c4f0302153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pYdP1-8l19j3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5269dd34-1b19-4a99-9e3d-593e978f3361",
      "metadata": {
        "id": "5269dd34-1b19-4a99-9e3d-593e978f3361"
      },
      "source": [
        "## 05. n-gram\n",
        "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ。この関数を用い、\"I am an NLPer\"という文から文字tri-gram、単語bi-gramを得よ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = 'I am an NLPer'\n",
        "\n",
        "def get_chracter_ngram(sequence, n):\n",
        "    ngram = []\n",
        "    for i in range(len(sequence) - n + 1):\n",
        "        ngram.append(sequence[i:i+n])\n",
        "    return ngram\n",
        "\n",
        "print(get_chracter_ngram(sequence, 3))\n",
        "\n",
        "def get_word_ngram(sequence, n):\n",
        "    sequence = sequence.replace(',', '')\n",
        "    sequence = sequence.replace('.', '')\n",
        "\n",
        "    words = sequence.split()\n",
        "    ngram = []\n",
        "    for i in range(len(words) - n + 1):\n",
        "        ngram.append(words[i:i+n])\n",
        "    return ngram\n",
        "\n",
        "print(get_word_ngram(sequence, 2))\n"
      ],
      "metadata": {
        "id": "CRj_UTaz3w4G",
        "outputId": "fb686990-5e4e-48df-aec5-14c227e69eb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CRj_UTaz3w4G",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I a', ' am', 'am ', 'm a', ' an', 'an ', 'n N', ' NL', 'NLP', 'LPe', 'Per']\n",
            "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15df1a31-7906-4562-b5c5-b52194487ea9",
      "metadata": {
        "id": "15df1a31-7906-4562-b5c5-b52194487ea9"
      },
      "source": [
        "## 06. 集合\n",
        "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を、それぞれ, $X$ と $Y$ として求め、$X$ と $Y$ の和集合（$X \\cup Y$）、積集合（$X \\cap Y$）、差集合（$X \\setminus Y$）を求めよ。さらに、'se'というbi-gramがXおよびYに含まれるかどうかを調べよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_x = 'paraparaparadise'\n",
        "word_y = 'paragraph'\n",
        "\n",
        "x = set(get_chracter_ngram(word_x, 2))\n",
        "y = set(get_chracter_ngram(word_y, 2))\n",
        "\n",
        "union = x | y\n",
        "intersection = x & y\n",
        "difference = x - y\n",
        "\n",
        "print('x set', x)\n",
        "print('y set', y)\n",
        "\n",
        "print('union set', union)\n",
        "print('intersection set', intersection)\n",
        "print('difference set', difference)\n",
        "\n",
        "print('se' in x)\n",
        "print('se' in y)"
      ],
      "metadata": {
        "id": "qj-RcU4x79RP",
        "outputId": "791ceb39-0bff-4310-cb75-81cd2cb23e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qj-RcU4x79RP",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x set {'is', 'di', 'ad', 'ra', 'ar', 'pa', 'se', 'ap'}\n",
            "y set {'gr', 'ag', 'ra', 'ar', 'pa', 'ph', 'ap'}\n",
            "union set {'gr', 'ag', 'is', 'di', 'ad', 'ra', 'ar', 'pa', 'se', 'ap', 'ph'}\n",
            "intersection set {'ra', 'ap', 'ar', 'pa'}\n",
            "difference set {'se', 'is', 'di', 'ad'}\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90b9bdde-e35c-4dc5-a46d-f7a8dd6d6513",
      "metadata": {
        "id": "90b9bdde-e35c-4dc5-a46d-f7a8dd6d6513"
      },
      "source": [
        "## 07. テンプレートによる文生成\n",
        "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ。さらに、x=12, y=\"気温\", z=22.4として、実行結果を確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def func(x, y, z):\n",
        "    return '{}時の{}は{}'.format(x, y, z)\n",
        "\n",
        "print(func(12, '気温', 22.4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJJ8GY55YktP",
        "outputId": "abcef854-c465-460a-b2ac-11cbe73f4d0f"
      },
      "id": "lJJ8GY55YktP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12時の気温は22.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "215bd86b-1b3c-4446-98ae-af5d671fba12",
      "metadata": {
        "id": "215bd86b-1b3c-4446-98ae-af5d671fba12"
      },
      "source": [
        "## 08. 暗号文\n",
        "与えられた文字列の各文字を、以下の仕様で変換する関数cipherを実装せよ。\n",
        "\n",
        "* 英小文字ならば (219 - 文字コード) のASCIIコードに対応する文字に置換\n",
        "* その他の文字はそのまま出力\n",
        "\n",
        "この関数を用い、英語のメッセージを暗号化・復号化せよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cipher(sequence):\n",
        "    for i in range(len(sequence)):\n",
        "        if sequence[i].islower():\n",
        "            sequence = sequence[:i] + chr(219 - ord(sequence[i])) + sequence[i+1:]\n",
        "    return sequence\n",
        "\n",
        "message = 'I am an NLPer'\n",
        "\n",
        "encrypted_message = cipher(message)\n",
        "print('encrypted message', encrypted_message)\n",
        "\n",
        "decrypted_message = cipher(encrypted_message)\n",
        "print('decrypted message', decrypted_message)\n",
        "\n"
      ],
      "metadata": {
        "id": "gPXeMppv-5Wr",
        "outputId": "1c747e50-8910-4231-f712-b4c6f53bd0b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gPXeMppv-5Wr",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encrypted message I zn zm NLPvi\n",
            "decrypted message I am an NLPer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c1bdae-5ce3-4128-86be-23ce079a2d98",
      "metadata": {
        "id": "64c1bdae-5ce3-4128-86be-23ce079a2d98"
      },
      "source": [
        "## 09. Typoglycemia\n",
        "スペースで区切られた単語列に対して、各単語の先頭と末尾の文字は残し、それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ。ただし、長さが４以下の単語は並び替えないこととする。適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え、その実行結果を確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "sentence = 'I couldn\\'t believe that I could actually understand what I was reading:thephenomenal power of the human mind .'\n",
        "words = sentence.split()\n",
        "\n",
        "res_sentence = ''\n",
        "for word in words:\n",
        "    if len(word) <= 4:\n",
        "        res_sentence += word + ' '\n",
        "    else:\n",
        "        word_head = word[0]\n",
        "        word_tail = word[-1]\n",
        "        word_middle = list(word[1:-1])\n",
        "        random.shuffle(word_middle)\n",
        "        shuffled_word = word_head + ''.join(word_middle) + word_tail\n",
        "        res_sentence += shuffled_word + ' '\n",
        "\n",
        "print('before shuffle', sentence)\n",
        "print('after shuffle', res_sentence)"
      ],
      "metadata": {
        "id": "MhYG7YL5CDCb",
        "outputId": "065f4278-3acd-40f8-8b1f-95a3b796cdcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MhYG7YL5CDCb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before shuffle I couldn't believe that I could actually understand what I was reading:thephenomenal power of the human mind .\n",
            "after shuffle I codnu'lt bveiele that I culod aaulclty unsradtend what I was rgp:eheoemhatineandnl pwoer of the haumn mind . \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}